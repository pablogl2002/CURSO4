{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S1. Red convolucional para MNIST\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como en la anterior práctica, primero importamos el conjunto de MNIST y lo normalizamos, pero sin convertir las imágenes en vectores unidimensionales, ya que vamos a trabajar con redes convolucionales que explotan la estructura 2D de las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set (60000, 28, 28)\n",
      "test set (10000, 28, 28)\n",
      "training set (48000, 28, 28)\n",
      "val set (12000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "## Importar y normalizar datos\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print('training set', x_train.shape)\n",
    "print('test set', x_test.shape)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalize [0..255]-->[0..1]\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "num_classes=10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print('training set', x_train.shape)\n",
    "print('val set', x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo base\n",
    " Partiremos de una topología base que toma la red MLP de la última sesión de la primera práctica (dos capas densas de 1024 neuronas), y le incorpora un par de capas convolucionales cada una seguida por average pooling inspirada en la arquitectura LeNet (1998) propuesta por Yann LeCun para MNIST. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.2652 - accuracy: 0.9224\n",
      "Epoch 1: val_accuracy improved from -inf to 0.97275, saving model to best_model.h5\n",
      "375/375 [==============================] - 5s 11ms/step - loss: 0.2645 - accuracy: 0.9226 - val_loss: 0.0914 - val_accuracy: 0.9728 - lr: 0.0010\n",
      "Epoch 2/25\n",
      " 10/375 [..............................] - ETA: 4s - loss: 0.0770 - accuracy: 0.9789"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pegi/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - ETA: 0s - loss: 0.0749 - accuracy: 0.9770\n",
      "Epoch 2: val_accuracy improved from 0.97275 to 0.98433, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0749 - accuracy: 0.9770 - val_loss: 0.0557 - val_accuracy: 0.9843 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0513 - accuracy: 0.9838\n",
      "Epoch 3: val_accuracy did not improve from 0.98433\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0513 - accuracy: 0.9838 - val_loss: 0.0530 - val_accuracy: 0.9843 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0396 - accuracy: 0.9876\n",
      "Epoch 4: val_accuracy improved from 0.98433 to 0.98592, saving model to best_model.h5\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.0396 - accuracy: 0.9876 - val_loss: 0.0502 - val_accuracy: 0.9859 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9899\n",
      "Epoch 5: val_accuracy improved from 0.98592 to 0.98617, saving model to best_model.h5\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.0324 - accuracy: 0.9899 - val_loss: 0.0545 - val_accuracy: 0.9862 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9912\n",
      "Epoch 6: val_accuracy did not improve from 0.98617\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0272 - accuracy: 0.9912 - val_loss: 0.0559 - val_accuracy: 0.9846 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9967\n",
      "Epoch 7: val_accuracy improved from 0.98617 to 0.99100, saving model to best_model.h5\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0115 - accuracy: 0.9967 - val_loss: 0.0350 - val_accuracy: 0.9910 - lr: 2.0000e-04\n",
      "Epoch 8/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9980\n",
      "Epoch 8: val_accuracy did not improve from 0.99100\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.0386 - val_accuracy: 0.9904 - lr: 2.0000e-04\n",
      "Epoch 9/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9982\n",
      "Epoch 9: val_accuracy did not improve from 0.99100\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.0400 - val_accuracy: 0.9898 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9991\n",
      "Epoch 10: val_accuracy did not improve from 0.99100\n",
      "375/375 [==============================] - 9s 23ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.0385 - val_accuracy: 0.9902 - lr: 4.0000e-05\n",
      "Epoch 11/25\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9992\n",
      "Epoch 11: val_accuracy did not improve from 0.99100\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.0394 - val_accuracy: 0.9901 - lr: 4.0000e-05\n",
      "Epoch 12/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9994\n",
      "Epoch 12: val_accuracy did not improve from 0.99100\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0395 - val_accuracy: 0.9902 - lr: 1.0000e-05\n",
      "Epoch 13/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9993\n",
      "Epoch 13: val_accuracy did not improve from 0.99100\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0399 - val_accuracy: 0.9900 - lr: 1.0000e-05\n",
      "Epoch 14/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9994\n",
      "Epoch 14: val_accuracy did not improve from 0.99100\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.0400 - val_accuracy: 0.9901 - lr: 1.0000e-05\n",
      "Epoch 15/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9994\n",
      "Epoch 15: val_accuracy did not improve from 0.99100\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0401 - val_accuracy: 0.9900 - lr: 1.0000e-05\n",
      "Epoch 16/25\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9994\n",
      "Epoch 16: val_accuracy did not improve from 0.99100\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0407 - val_accuracy: 0.9900 - lr: 1.0000e-05\n",
      "Epoch 17/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 17: val_accuracy did not improve from 0.99100\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.0410 - val_accuracy: 0.9901 - lr: 1.0000e-05\n",
      "Epoch 18/25\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9994\n",
      "Epoch 18: val_accuracy did not improve from 0.99100\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0411 - val_accuracy: 0.9898 - lr: 1.0000e-05\n",
      "Epoch 19/25\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9995\n",
      "Epoch 19: val_accuracy did not improve from 0.99100\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0413 - val_accuracy: 0.9901 - lr: 1.0000e-05\n",
      "Epoch 20/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9994\n",
      "Epoch 20: val_accuracy did not improve from 0.99100\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.0417 - val_accuracy: 0.9902 - lr: 1.0000e-05\n",
      "Epoch 21/25\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9995\n",
      "Epoch 21: val_accuracy did not improve from 0.99100\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0420 - val_accuracy: 0.9898 - lr: 1.0000e-05\n",
      "Epoch 22/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9995\n",
      "Epoch 22: val_accuracy did not improve from 0.99100\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0425 - val_accuracy: 0.9898 - lr: 1.0000e-05\n",
      "Epoch 23/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9995\n",
      "Epoch 23: val_accuracy did not improve from 0.99100\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.0426 - val_accuracy: 0.9901 - lr: 1.0000e-05\n",
      "Epoch 24/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9995\n",
      "Epoch 24: val_accuracy did not improve from 0.99100\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.0430 - val_accuracy: 0.9901 - lr: 1.0000e-05\n",
      "Epoch 25/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9995\n",
      "Epoch 25: val_accuracy did not improve from 0.99100\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0432 - val_accuracy: 0.9902 - lr: 1.0000e-05\n",
      "Test loss: 2.52\n",
      "Test accuracy: 99.16\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Input, Conv2D, AveragePooling2D, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input((28,28,1)))\n",
    "model.add(Conv2D(filters=6, kernel_size=(5,5), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(AveragePooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(Conv2D(filters=16, kernel_size=(5,5), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=1024, activation='relu'))\n",
    "model.add(Dense(units=1024, activation='relu'))\n",
    "model.add(Dense(units=10, activation = 'softmax'))\n",
    "\n",
    "opt=Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer=opt,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.00001)\n",
    "checkpoint = ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "\n",
    "epochs=25\n",
    "batch_size=128\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[reduce_lr,checkpoint])  \n",
    "\n",
    "## Cargar el mejor modelo y evaluarlo con el test set\n",
    "model = keras.models.load_model('best_model.h5')\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f'Test loss: {score[0]*100:.2f}')\n",
    "print(f'Test accuracy: {score[1]*100:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio:\n",
    "\n",
    "Probar las técnicas presentadas en la práctica 1 (dropout, batchnorm y aumento de datos) para obtener un acierto en test > 99%, incluso mejor que la obtenida con redes MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.1671 - accuracy: 0.9483\n",
      "Epoch 1: val_accuracy improved from -inf to 0.93042, saving model to best_model.h5\n",
      "375/375 [==============================] - 7s 14ms/step - loss: 0.1669 - accuracy: 0.9484 - val_loss: 0.3761 - val_accuracy: 0.9304 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0655 - accuracy: 0.9798\n",
      "Epoch 2: val_accuracy improved from 0.93042 to 0.98467, saving model to best_model.h5\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.0655 - accuracy: 0.9798 - val_loss: 0.0554 - val_accuracy: 0.9847 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 0.9852\n",
      "Epoch 3: val_accuracy did not improve from 0.98467\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.0481 - accuracy: 0.9852 - val_loss: 0.0580 - val_accuracy: 0.9847 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0404 - accuracy: 0.9874\n",
      "Epoch 4: val_accuracy improved from 0.98467 to 0.98567, saving model to best_model.h5\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.0404 - accuracy: 0.9874 - val_loss: 0.0509 - val_accuracy: 0.9857 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0332 - accuracy: 0.9897\n",
      "Epoch 5: val_accuracy improved from 0.98567 to 0.98792, saving model to best_model.h5\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.0331 - accuracy: 0.9897 - val_loss: 0.0411 - val_accuracy: 0.9879 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0271 - accuracy: 0.9913\n",
      "Epoch 6: val_accuracy did not improve from 0.98792\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.0273 - accuracy: 0.9913 - val_loss: 0.0513 - val_accuracy: 0.9852 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 0.9909\n",
      "Epoch 7: val_accuracy did not improve from 0.98792\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.0279 - accuracy: 0.9909 - val_loss: 0.0628 - val_accuracy: 0.9852 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9954\n",
      "Epoch 8: val_accuracy improved from 0.98792 to 0.99158, saving model to best_model.h5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.0302 - val_accuracy: 0.9916 - lr: 2.0000e-04\n",
      "Epoch 9/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.9974\n",
      "Epoch 9: val_accuracy improved from 0.99158 to 0.99233, saving model to best_model.h5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.0284 - val_accuracy: 0.9923 - lr: 2.0000e-04\n",
      "Epoch 10/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9976\n",
      "Epoch 10: val_accuracy improved from 0.99233 to 0.99258, saving model to best_model.h5\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0275 - val_accuracy: 0.9926 - lr: 2.0000e-04\n",
      "Epoch 11/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9980\n",
      "Epoch 11: val_accuracy did not improve from 0.99258\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.0285 - val_accuracy: 0.9923 - lr: 2.0000e-04\n",
      "Epoch 12/25\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9985\n",
      "Epoch 12: val_accuracy did not improve from 0.99258\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0282 - val_accuracy: 0.9923 - lr: 2.0000e-04\n",
      "Epoch 13/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9990\n",
      "Epoch 13: val_accuracy improved from 0.99258 to 0.99300, saving model to best_model.h5\n",
      "375/375 [==============================] - 8s 23ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0278 - val_accuracy: 0.9930 - lr: 4.0000e-05\n",
      "Epoch 14/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9991\n",
      "Epoch 14: val_accuracy improved from 0.99300 to 0.99308, saving model to best_model.h5\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 0.0274 - val_accuracy: 0.9931 - lr: 4.0000e-05\n",
      "Epoch 15/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9991\n",
      "Epoch 15: val_accuracy did not improve from 0.99308\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0277 - val_accuracy: 0.9931 - lr: 4.0000e-05\n",
      "Epoch 16/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9991\n",
      "Epoch 16: val_accuracy did not improve from 0.99308\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0273 - val_accuracy: 0.9926 - lr: 4.0000e-05\n",
      "Epoch 17/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 17: val_accuracy did not improve from 0.99308\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0272 - val_accuracy: 0.9928 - lr: 1.0000e-05\n",
      "Epoch 18/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 18: val_accuracy did not improve from 0.99308\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0273 - val_accuracy: 0.9928 - lr: 1.0000e-05\n",
      "Epoch 19/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9992\n",
      "Epoch 19: val_accuracy did not improve from 0.99308\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0272 - val_accuracy: 0.9927 - lr: 1.0000e-05\n",
      "Epoch 20/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9994\n",
      "Epoch 20: val_accuracy did not improve from 0.99308\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0274 - val_accuracy: 0.9929 - lr: 1.0000e-05\n",
      "Epoch 21/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 21: val_accuracy did not improve from 0.99308\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0275 - val_accuracy: 0.9931 - lr: 1.0000e-05\n",
      "Epoch 22/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 22: val_accuracy did not improve from 0.99308\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0275 - val_accuracy: 0.9927 - lr: 1.0000e-05\n",
      "Epoch 23/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9994\n",
      "Epoch 23: val_accuracy did not improve from 0.99308\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0274 - val_accuracy: 0.9930 - lr: 1.0000e-05\n",
      "Epoch 24/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 24: val_accuracy improved from 0.99308 to 0.99317, saving model to best_model.h5\n",
      "375/375 [==============================] - 12s 33ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0275 - val_accuracy: 0.9932 - lr: 1.0000e-05\n",
      "Epoch 25/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9996\n",
      "Epoch 25: val_accuracy did not improve from 0.99317\n",
      "375/375 [==============================] - 12s 32ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.0276 - val_accuracy: 0.9929 - lr: 1.0000e-05\n",
      "Test loss: 1.83\n",
      "Test accuracy: 99.45\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Input, Conv2D, AveragePooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input((28,28,1)))\n",
    "model.add(Conv2D(filters=6, kernel_size=(5,5), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(AveragePooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(Conv2D(filters=16, kernel_size=(5,5), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=10, activation = 'softmax'))\n",
    "\n",
    "opt=Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer=opt,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.00001)\n",
    "checkpoint = ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "\n",
    "epochs=25\n",
    "batch_size=128\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[reduce_lr,checkpoint])  \n",
    "\n",
    "## Cargar el mejor modelo y evaluarlo con el test set\n",
    "model = keras.models.load_model('best_model.h5')\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f'Test loss: {score[0]*100:.2f}')\n",
    "print(f'Test accuracy: {score[1]*100:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P4 Regularización, Normalización y Aumentado de datos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-15 17:43:47.678877: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-15 17:43:47.730721: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-15 17:43:47.915319: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-15 17:43:47.915347: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-15 17:43:47.916463: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-15 17:43:47.991764: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-15 17:43:47.992925: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-15 17:43:48.923838: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set (60000, 28, 28)\n",
      "test set (10000, 28, 28)\n",
      "training set (48000, 784)\n",
      "val set (12000, 784)\n"
     ]
    }
   ],
   "source": [
    "## Importar y normalizar datos\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print('training set', x_train.shape)\n",
    "print('test set', x_test.shape)\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalize [0..255]-->[0..1]\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "num_classes=10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print('training set', x_train.shape)\n",
    "print('val set', x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo base\n",
    " Partiremos de una topología base e iremos añadiendo diferentes estrategias de regularización para mejorar el rendimiento del modelo.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.3417 - accuracy: 0.9010\n",
      "Epoch 1: val_accuracy improved from -inf to 0.95133, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.3399 - accuracy: 0.9016 - val_loss: 0.1709 - val_accuracy: 0.9513 - lr: 0.0250\n",
      "Epoch 2/25\n",
      " 23/375 [>.............................] - ETA: 2s - loss: 0.1529 - accuracy: 0.9558"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pegi/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371/375 [============================>.] - ETA: 0s - loss: 0.1347 - accuracy: 0.9606\n",
      "Epoch 2: val_accuracy improved from 0.95133 to 0.96083, saving model to best_model.h5\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.1344 - accuracy: 0.9606 - val_loss: 0.1289 - val_accuracy: 0.9608 - lr: 0.0250\n",
      "Epoch 3/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0892 - accuracy: 0.9742\n",
      "Epoch 3: val_accuracy improved from 0.96083 to 0.96967, saving model to best_model.h5\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0892 - accuracy: 0.9742 - val_loss: 0.1051 - val_accuracy: 0.9697 - lr: 0.0250\n",
      "Epoch 4/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 0.9814\n",
      "Epoch 4: val_accuracy improved from 0.96967 to 0.97217, saving model to best_model.h5\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.0635 - accuracy: 0.9814 - val_loss: 0.0893 - val_accuracy: 0.9722 - lr: 0.0250\n",
      "Epoch 5/25\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0483 - accuracy: 0.9858\n",
      "Epoch 5: val_accuracy improved from 0.97217 to 0.97608, saving model to best_model.h5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0483 - accuracy: 0.9859 - val_loss: 0.0774 - val_accuracy: 0.9761 - lr: 0.0250\n",
      "Epoch 6/25\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0355 - accuracy: 0.9903\n",
      "Epoch 6: val_accuracy improved from 0.97608 to 0.97708, saving model to best_model.h5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0355 - accuracy: 0.9903 - val_loss: 0.0749 - val_accuracy: 0.9771 - lr: 0.0250\n",
      "Epoch 7/25\n",
      "369/375 [============================>.] - ETA: 0s - loss: 0.0271 - accuracy: 0.9926\n",
      "Epoch 7: val_accuracy did not improve from 0.97708\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0270 - accuracy: 0.9926 - val_loss: 0.0779 - val_accuracy: 0.9766 - lr: 0.0250\n",
      "Epoch 8/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.9953\n",
      "Epoch 8: val_accuracy improved from 0.97708 to 0.97892, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0202 - accuracy: 0.9953 - val_loss: 0.0714 - val_accuracy: 0.9789 - lr: 0.0250\n",
      "Epoch 9/25\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9971\n",
      "Epoch 9: val_accuracy improved from 0.97892 to 0.98042, saving model to best_model.h5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0145 - accuracy: 0.9971 - val_loss: 0.0697 - val_accuracy: 0.9804 - lr: 0.0250\n",
      "Epoch 10/25\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.9980\n",
      "Epoch 10: val_accuracy improved from 0.98042 to 0.98117, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0108 - accuracy: 0.9980 - val_loss: 0.0670 - val_accuracy: 0.9812 - lr: 0.0250\n",
      "Epoch 11/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9988\n",
      "Epoch 11: val_accuracy did not improve from 0.98117\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0078 - accuracy: 0.9988 - val_loss: 0.0654 - val_accuracy: 0.9809 - lr: 0.0250\n",
      "Epoch 12/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9993\n",
      "Epoch 12: val_accuracy did not improve from 0.98117\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0064 - accuracy: 0.9992 - val_loss: 0.0695 - val_accuracy: 0.9807 - lr: 0.0250\n",
      "Epoch 13/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9996\n",
      "Epoch 13: val_accuracy improved from 0.98117 to 0.98200, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.0048 - accuracy: 0.9996 - val_loss: 0.0683 - val_accuracy: 0.9820 - lr: 0.0250\n",
      "Epoch 14/25\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9999\n",
      "Epoch 14: val_accuracy improved from 0.98200 to 0.98225, saving model to best_model.h5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.0682 - val_accuracy: 0.9822 - lr: 0.0050\n",
      "Epoch 15/25\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9999\n",
      "Epoch 15: val_accuracy improved from 0.98225 to 0.98233, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.0678 - val_accuracy: 0.9823 - lr: 0.0050\n",
      "Epoch 16/25\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 16: val_accuracy improved from 0.98233 to 0.98258, saving model to best_model.h5\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0678 - val_accuracy: 0.9826 - lr: 1.0000e-03\n",
      "Epoch 17/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 17: val_accuracy did not improve from 0.98258\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9825 - lr: 1.0000e-03\n",
      "Epoch 18/25\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 18: val_accuracy did not improve from 0.98258\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9826 - lr: 2.0000e-04\n",
      "Epoch 19/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 19: val_accuracy did not improve from 0.98258\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9826 - lr: 2.0000e-04\n",
      "Epoch 20/25\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 20: val_accuracy did not improve from 0.98258\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9826 - lr: 4.0000e-05\n",
      "Epoch 21/25\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 21: val_accuracy did not improve from 0.98258\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9826 - lr: 4.0000e-05\n",
      "Epoch 22/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 22: val_accuracy did not improve from 0.98258\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9826 - lr: 1.0000e-05\n",
      "Epoch 23/25\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 23: val_accuracy did not improve from 0.98258\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9826 - lr: 1.0000e-05\n",
      "Epoch 24/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 24: val_accuracy did not improve from 0.98258\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9826 - lr: 1.0000e-05\n",
      "Epoch 25/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 25: val_accuracy did not improve from 0.98258\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0679 - val_accuracy: 0.9826 - lr: 1.0000e-05\n",
      "Test loss: 0.06158742681145668\n",
      "Test accuracy: 0.9818000197410583\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(784))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "opt=SGD(learning_rate=0.025, momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer=opt,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                                patience=2, min_lr=0.00001)\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "\n",
    "\n",
    "epochs=25\n",
    "batch_size=128\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[reduce_lr,checkpoint])  \n",
    "\n",
    "## Cargar el mejor modelo y evaluarlo con el test set\n",
    "model = keras.models.load_model('best_model.h5')\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularización l2 (o l1)\n",
    "\n",
    "La regularización l2 consiste en añadir a la función de coste una penalización proporcional a la norma l2 de los pesos del modelo. De esta forma, se penaliza a los pesos que tengan un valor alto, forzando a que los pesos tengan valores pequeños. Esto se conoce como regularización l2. También podríamos hacer lo mismo con regularización l1 o con ambas (lo que se conoce como *Elastic net*)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 5.8529 - accuracy: 0.8834\n",
      "Epoch 1: val_accuracy improved from -inf to 0.92217, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 5.8529 - accuracy: 0.8834 - val_loss: 0.9253 - val_accuracy: 0.9222 - lr: 0.0250\n",
      "Epoch 2/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.5756 - accuracy: 0.9292\n",
      "Epoch 2: val_accuracy improved from 0.92217 to 0.94008, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5746 - accuracy: 0.9294 - val_loss: 0.4420 - val_accuracy: 0.9401 - lr: 0.0250\n",
      "Epoch 3/25\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.4281 - accuracy: 0.9393\n",
      "Epoch 3: val_accuracy improved from 0.94008 to 0.94217, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.4279 - accuracy: 0.9394 - val_loss: 0.4156 - val_accuracy: 0.9422 - lr: 0.0250\n",
      "Epoch 4/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.4032 - accuracy: 0.9441\n",
      "Epoch 4: val_accuracy improved from 0.94217 to 0.94933, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4032 - accuracy: 0.9441 - val_loss: 0.3828 - val_accuracy: 0.9493 - lr: 0.0250\n",
      "Epoch 5/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.3862 - accuracy: 0.9462\n",
      "Epoch 5: val_accuracy did not improve from 0.94933\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.3861 - accuracy: 0.9463 - val_loss: 0.3788 - val_accuracy: 0.9483 - lr: 0.0250\n",
      "Epoch 6/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.3732 - accuracy: 0.9489\n",
      "Epoch 6: val_accuracy did not improve from 0.94933\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.3735 - accuracy: 0.9488 - val_loss: 0.3700 - val_accuracy: 0.9487 - lr: 0.0250\n",
      "Epoch 7/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.3642 - accuracy: 0.9509\n",
      "Epoch 7: val_accuracy improved from 0.94933 to 0.95133, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3643 - accuracy: 0.9509 - val_loss: 0.3616 - val_accuracy: 0.9513 - lr: 0.0250\n",
      "Epoch 8/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.3584 - accuracy: 0.9501\n",
      "Epoch 8: val_accuracy improved from 0.95133 to 0.95142, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3583 - accuracy: 0.9502 - val_loss: 0.3525 - val_accuracy: 0.9514 - lr: 0.0250\n",
      "Epoch 9/25\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.3495 - accuracy: 0.9514\n",
      "Epoch 9: val_accuracy did not improve from 0.95142\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.3493 - accuracy: 0.9514 - val_loss: 0.3635 - val_accuracy: 0.9452 - lr: 0.0250\n",
      "Epoch 10/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.3460 - accuracy: 0.9523\n",
      "Epoch 10: val_accuracy improved from 0.95142 to 0.95317, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.3460 - accuracy: 0.9523 - val_loss: 0.3412 - val_accuracy: 0.9532 - lr: 0.0250\n",
      "Epoch 11/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.3436 - accuracy: 0.9524\n",
      "Epoch 11: val_accuracy did not improve from 0.95317\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3438 - accuracy: 0.9523 - val_loss: 0.3504 - val_accuracy: 0.9518 - lr: 0.0250\n",
      "Epoch 12/25\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.3423 - accuracy: 0.9525\n",
      "Epoch 12: val_accuracy did not improve from 0.95317\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3417 - accuracy: 0.9527 - val_loss: 0.3518 - val_accuracy: 0.9496 - lr: 0.0250\n",
      "Epoch 13/25\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.2945 - accuracy: 0.9658\n",
      "Epoch 13: val_accuracy improved from 0.95317 to 0.96483, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2943 - accuracy: 0.9658 - val_loss: 0.2919 - val_accuracy: 0.9648 - lr: 0.0050\n",
      "Epoch 14/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.2807 - accuracy: 0.9685\n",
      "Epoch 14: val_accuracy did not improve from 0.96483\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2808 - accuracy: 0.9685 - val_loss: 0.2884 - val_accuracy: 0.9633 - lr: 0.0050\n",
      "Epoch 15/25\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.2774 - accuracy: 0.9689\n",
      "Epoch 15: val_accuracy improved from 0.96483 to 0.96600, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2775 - accuracy: 0.9688 - val_loss: 0.2835 - val_accuracy: 0.9660 - lr: 0.0050\n",
      "Epoch 16/25\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.2761 - accuracy: 0.9690\n",
      "Epoch 16: val_accuracy did not improve from 0.96600\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2757 - accuracy: 0.9691 - val_loss: 0.2811 - val_accuracy: 0.9653 - lr: 0.0050\n",
      "Epoch 17/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.2751 - accuracy: 0.9689\n",
      "Epoch 17: val_accuracy improved from 0.96600 to 0.96642, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2752 - accuracy: 0.9688 - val_loss: 0.2821 - val_accuracy: 0.9664 - lr: 0.0050\n",
      "Epoch 18/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.2735 - accuracy: 0.9690\n",
      "Epoch 18: val_accuracy did not improve from 0.96642\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2735 - accuracy: 0.9690 - val_loss: 0.2819 - val_accuracy: 0.9659 - lr: 0.0050\n",
      "Epoch 19/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.2645 - accuracy: 0.9719\n",
      "Epoch 19: val_accuracy improved from 0.96642 to 0.96817, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2644 - accuracy: 0.9720 - val_loss: 0.2764 - val_accuracy: 0.9682 - lr: 1.0000e-03\n",
      "Epoch 20/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.2632 - accuracy: 0.9725\n",
      "Epoch 20: val_accuracy did not improve from 0.96817\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2632 - accuracy: 0.9725 - val_loss: 0.2756 - val_accuracy: 0.9672 - lr: 1.0000e-03\n",
      "Epoch 21/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.2625 - accuracy: 0.9722\n",
      "Epoch 21: val_accuracy did not improve from 0.96817\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2625 - accuracy: 0.9722 - val_loss: 0.2748 - val_accuracy: 0.9675 - lr: 1.0000e-03\n",
      "Epoch 22/25\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.2624 - accuracy: 0.9727\n",
      "Epoch 22: val_accuracy did not improve from 0.96817\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2623 - accuracy: 0.9728 - val_loss: 0.2751 - val_accuracy: 0.9673 - lr: 1.0000e-03\n",
      "Epoch 23/25\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.2619 - accuracy: 0.9725\n",
      "Epoch 23: val_accuracy did not improve from 0.96817\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2620 - accuracy: 0.9724 - val_loss: 0.2748 - val_accuracy: 0.9678 - lr: 1.0000e-03\n",
      "Epoch 24/25\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.2600 - accuracy: 0.9733\n",
      "Epoch 24: val_accuracy did not improve from 0.96817\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2601 - accuracy: 0.9734 - val_loss: 0.2741 - val_accuracy: 0.9679 - lr: 2.0000e-04\n",
      "Epoch 25/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.2597 - accuracy: 0.9735\n",
      "Epoch 25: val_accuracy did not improve from 0.96817\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2597 - accuracy: 0.9735 - val_loss: 0.2737 - val_accuracy: 0.9682 - lr: 2.0000e-04\n",
      "Test loss: 0.2692805528640747\n",
      "Test accuracy: 0.9692000150680542\n"
     ]
    }
   ],
   "source": [
    "## Teniendo en cuenta el modelo base añade regularización L2 a las capas densas\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.regularizers import l2\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(784))\n",
    "model.add(Dense(1024, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dense(1024, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "opt=SGD(learning_rate=0.025, momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer=opt,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                                patience=2, min_lr=0.00001)\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "\n",
    "\n",
    "epochs=25\n",
    "batch_size=128\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[reduce_lr,checkpoint])  \n",
    "\n",
    "## Cargar el mejor modelo y evaluarlo con el test set\n",
    "model = keras.models.load_model('best_model.h5')\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "\n",
    "El dropout es una técnica de regularización que consiste en eliminar aleatoriamente un porcentaje de las neuronas de la red durante el entrenamiento. De esta forma, se evita que la red se sobreajuste a los datos de entrenamiento y se mejora la generalización del modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.4471 - accuracy: 0.8617\n",
      "Epoch 1: val_accuracy improved from -inf to 0.94692, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.4471 - accuracy: 0.8617 - val_loss: 0.1717 - val_accuracy: 0.9469 - lr: 0.0250\n",
      "Epoch 2/25\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.1925 - accuracy: 0.9422\n",
      "Epoch 2: val_accuracy improved from 0.94692 to 0.96108, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1921 - accuracy: 0.9423 - val_loss: 0.1273 - val_accuracy: 0.9611 - lr: 0.0250\n",
      "Epoch 3/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.1460 - accuracy: 0.9549\n",
      "Epoch 3: val_accuracy improved from 0.96108 to 0.96917, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1457 - accuracy: 0.9550 - val_loss: 0.1026 - val_accuracy: 0.9692 - lr: 0.0250\n",
      "Epoch 4/25\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.1176 - accuracy: 0.9639\n",
      "Epoch 4: val_accuracy improved from 0.96917 to 0.97258, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.1173 - accuracy: 0.9641 - val_loss: 0.0915 - val_accuracy: 0.9726 - lr: 0.0250\n",
      "Epoch 5/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0995 - accuracy: 0.9698\n",
      "Epoch 5: val_accuracy improved from 0.97258 to 0.97417, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0995 - accuracy: 0.9698 - val_loss: 0.0848 - val_accuracy: 0.9742 - lr: 0.0250\n",
      "Epoch 6/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0883 - accuracy: 0.9722\n",
      "Epoch 6: val_accuracy improved from 0.97417 to 0.97675, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0884 - accuracy: 0.9722 - val_loss: 0.0778 - val_accuracy: 0.9768 - lr: 0.0250\n",
      "Epoch 7/25\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0759 - accuracy: 0.9767\n",
      "Epoch 7: val_accuracy improved from 0.97675 to 0.97808, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0760 - accuracy: 0.9766 - val_loss: 0.0738 - val_accuracy: 0.9781 - lr: 0.0250\n",
      "Epoch 8/25\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0732 - accuracy: 0.9765\n",
      "Epoch 8: val_accuracy improved from 0.97808 to 0.97950, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0733 - accuracy: 0.9765 - val_loss: 0.0671 - val_accuracy: 0.9795 - lr: 0.0250\n",
      "Epoch 9/25\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0641 - accuracy: 0.9794\n",
      "Epoch 9: val_accuracy improved from 0.97950 to 0.98100, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0641 - accuracy: 0.9794 - val_loss: 0.0642 - val_accuracy: 0.9810 - lr: 0.0250\n",
      "Epoch 10/25\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0604 - accuracy: 0.9805\n",
      "Epoch 10: val_accuracy did not improve from 0.98100\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0603 - accuracy: 0.9805 - val_loss: 0.0676 - val_accuracy: 0.9804 - lr: 0.0250\n",
      "Epoch 11/25\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0533 - accuracy: 0.9828\n",
      "Epoch 11: val_accuracy did not improve from 0.98100\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.0533 - accuracy: 0.9829 - val_loss: 0.0687 - val_accuracy: 0.9796 - lr: 0.0250\n",
      "Epoch 12/25\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0425 - accuracy: 0.9862\n",
      "Epoch 12: val_accuracy improved from 0.98100 to 0.98167, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.0424 - accuracy: 0.9862 - val_loss: 0.0630 - val_accuracy: 0.9817 - lr: 0.0050\n",
      "Epoch 13/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.9890\n",
      "Epoch 13: val_accuracy improved from 0.98167 to 0.98242, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0363 - accuracy: 0.9890 - val_loss: 0.0608 - val_accuracy: 0.9824 - lr: 0.0050\n",
      "Epoch 14/25\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0342 - accuracy: 0.9891\n",
      "Epoch 14: val_accuracy improved from 0.98242 to 0.98267, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.0343 - accuracy: 0.9891 - val_loss: 0.0600 - val_accuracy: 0.9827 - lr: 0.0050\n",
      "Epoch 15/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0338 - accuracy: 0.9892\n",
      "Epoch 15: val_accuracy did not improve from 0.98267\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0337 - accuracy: 0.9893 - val_loss: 0.0607 - val_accuracy: 0.9824 - lr: 0.0050\n",
      "Epoch 16/25\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0325 - accuracy: 0.9897\n",
      "Epoch 16: val_accuracy did not improve from 0.98267\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0323 - accuracy: 0.9898 - val_loss: 0.0600 - val_accuracy: 0.9818 - lr: 0.0050\n",
      "Epoch 17/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0296 - accuracy: 0.9909\n",
      "Epoch 17: val_accuracy improved from 0.98267 to 0.98308, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0295 - accuracy: 0.9909 - val_loss: 0.0593 - val_accuracy: 0.9831 - lr: 1.0000e-03\n",
      "Epoch 18/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9912\n",
      "Epoch 18: val_accuracy did not improve from 0.98308\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0292 - accuracy: 0.9912 - val_loss: 0.0602 - val_accuracy: 0.9825 - lr: 1.0000e-03\n",
      "Epoch 19/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0283 - accuracy: 0.9915\n",
      "Epoch 19: val_accuracy did not improve from 0.98308\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0283 - accuracy: 0.9916 - val_loss: 0.0600 - val_accuracy: 0.9825 - lr: 1.0000e-03\n",
      "Epoch 20/25\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0273 - accuracy: 0.9915\n",
      "Epoch 20: val_accuracy did not improve from 0.98308\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0272 - accuracy: 0.9915 - val_loss: 0.0598 - val_accuracy: 0.9823 - lr: 2.0000e-04\n",
      "Epoch 21/25\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0276 - accuracy: 0.9919\n",
      "Epoch 21: val_accuracy did not improve from 0.98308\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0276 - accuracy: 0.9919 - val_loss: 0.0597 - val_accuracy: 0.9826 - lr: 2.0000e-04\n",
      "Epoch 22/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.9920\n",
      "Epoch 22: val_accuracy did not improve from 0.98308\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0284 - accuracy: 0.9920 - val_loss: 0.0597 - val_accuracy: 0.9826 - lr: 4.0000e-05\n",
      "Epoch 23/25\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0276 - accuracy: 0.9913\n",
      "Epoch 23: val_accuracy did not improve from 0.98308\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0276 - accuracy: 0.9913 - val_loss: 0.0597 - val_accuracy: 0.9825 - lr: 4.0000e-05\n",
      "Epoch 24/25\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9919\n",
      "Epoch 24: val_accuracy did not improve from 0.98308\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0277 - accuracy: 0.9918 - val_loss: 0.0597 - val_accuracy: 0.9826 - lr: 1.0000e-05\n",
      "Epoch 25/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0279 - accuracy: 0.9917\n",
      "Epoch 25: val_accuracy did not improve from 0.98308\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0280 - accuracy: 0.9917 - val_loss: 0.0597 - val_accuracy: 0.9826 - lr: 1.0000e-05\n",
      "Test loss: 0.055523235350847244\n",
      "Test accuracy: 0.9836999773979187\n"
     ]
    }
   ],
   "source": [
    "## Teniendo en cuenta el modelo base añade regularización de tipo dropout a las capas densas\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.regularizers import l2\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(784))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "opt=SGD(learning_rate=0.025, momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer=opt,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                                patience=2, min_lr=0.00001)\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "\n",
    "\n",
    "epochs=25\n",
    "batch_size=128\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[reduce_lr,checkpoint])  \n",
    "\n",
    "## Cargar el mejor modelo y evaluarlo con el test set\n",
    "model = keras.models.load_model('best_model.h5')\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalización BatchNorm\n",
    "\n",
    "La normalización BatchNorm consiste en normalizar la salida de una capa de la red neuronal para que tenga media 0 y varianza 1. De esta forma, se consigue que la red neuronal pueda entrenarse más rápido y que sea más robusta a cambios en los pesos de las capas anteriores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.2096 - accuracy: 0.9403\n",
      "Epoch 1: val_accuracy improved from -inf to 0.96333, saving model to best_model.h5\n",
      "375/375 [==============================] - 5s 11ms/step - loss: 0.2080 - accuracy: 0.9406 - val_loss: 0.1223 - val_accuracy: 0.9633 - lr: 0.0250\n",
      "Epoch 2/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0647 - accuracy: 0.9795\n",
      "Epoch 2: val_accuracy improved from 0.96333 to 0.97208, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0647 - accuracy: 0.9795 - val_loss: 0.1025 - val_accuracy: 0.9721 - lr: 0.0250\n",
      "Epoch 3/25\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0363 - accuracy: 0.9876\n",
      "Epoch 3: val_accuracy improved from 0.97208 to 0.97600, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0364 - accuracy: 0.9876 - val_loss: 0.0838 - val_accuracy: 0.9760 - lr: 0.0250\n",
      "Epoch 4/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.9942\n",
      "Epoch 4: val_accuracy improved from 0.97600 to 0.97917, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0191 - accuracy: 0.9942 - val_loss: 0.0823 - val_accuracy: 0.9792 - lr: 0.0250\n",
      "Epoch 5/25\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9956\n",
      "Epoch 5: val_accuracy did not improve from 0.97917\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0144 - accuracy: 0.9956 - val_loss: 0.0842 - val_accuracy: 0.9786 - lr: 0.0250\n",
      "Epoch 6/25\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 0.9972\n",
      "Epoch 6: val_accuracy improved from 0.97917 to 0.98042, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.0773 - val_accuracy: 0.9804 - lr: 0.0250\n",
      "Epoch 7/25\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9981\n",
      "Epoch 7: val_accuracy improved from 0.98042 to 0.98258, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0731 - val_accuracy: 0.9826 - lr: 0.0250\n",
      "Epoch 8/25\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 8: val_accuracy improved from 0.98258 to 0.98300, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.0732 - val_accuracy: 0.9830 - lr: 0.0250\n",
      "Epoch 9/25\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9999\n",
      "Epoch 9: val_accuracy improved from 0.98300 to 0.98408, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0697 - val_accuracy: 0.9841 - lr: 0.0250\n",
      "Epoch 10/25\n",
      "371/375 [============================>.] - ETA: 0s - loss: 9.2634e-04 - accuracy: 0.9999\n",
      "Epoch 10: val_accuracy improved from 0.98408 to 0.98442, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 9.2265e-04 - accuracy: 0.9999 - val_loss: 0.0691 - val_accuracy: 0.9844 - lr: 0.0250\n",
      "Epoch 11/25\n",
      "371/375 [============================>.] - ETA: 0s - loss: 6.8345e-04 - accuracy: 1.0000\n",
      "Epoch 11: val_accuracy did not improve from 0.98442\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 6.8585e-04 - accuracy: 1.0000 - val_loss: 0.0708 - val_accuracy: 0.9844 - lr: 0.0250\n",
      "Epoch 12/25\n",
      "371/375 [============================>.] - ETA: 0s - loss: 5.1766e-04 - accuracy: 1.0000\n",
      "Epoch 12: val_accuracy improved from 0.98442 to 0.98508, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 5.1970e-04 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 0.9851 - lr: 0.0250\n",
      "Epoch 13/25\n",
      "372/375 [============================>.] - ETA: 0s - loss: 4.0425e-04 - accuracy: 1.0000\n",
      "Epoch 13: val_accuracy did not improve from 0.98508\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 4.0628e-04 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9851 - lr: 0.0050\n",
      "Epoch 14/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 3.7027e-04 - accuracy: 1.0000\n",
      "Epoch 14: val_accuracy did not improve from 0.98508\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 3.7072e-04 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 0.9851 - lr: 0.0050\n",
      "Epoch 15/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 3.5009e-04 - accuracy: 1.0000\n",
      "Epoch 15: val_accuracy did not improve from 0.98508\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 3.4905e-04 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9851 - lr: 0.0050\n",
      "Epoch 16/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 3.4173e-04 - accuracy: 1.0000\n",
      "Epoch 16: val_accuracy improved from 0.98508 to 0.98517, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 3.4180e-04 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 0.9852 - lr: 0.0050\n",
      "Epoch 17/25\n",
      "370/375 [============================>.] - ETA: 0s - loss: 3.3362e-04 - accuracy: 1.0000\n",
      "Epoch 17: val_accuracy did not improve from 0.98517\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 3.3438e-04 - accuracy: 1.0000 - val_loss: 0.0693 - val_accuracy: 0.9852 - lr: 1.0000e-03\n",
      "Epoch 18/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 3.2672e-04 - accuracy: 1.0000\n",
      "Epoch 18: val_accuracy did not improve from 0.98517\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 3.2672e-04 - accuracy: 1.0000 - val_loss: 0.0689 - val_accuracy: 0.9852 - lr: 1.0000e-03\n",
      "Epoch 19/25\n",
      "372/375 [============================>.] - ETA: 0s - loss: 3.2929e-04 - accuracy: 1.0000\n",
      "Epoch 19: val_accuracy improved from 0.98517 to 0.98525, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 3.2835e-04 - accuracy: 1.0000 - val_loss: 0.0692 - val_accuracy: 0.9852 - lr: 2.0000e-04\n",
      "Epoch 20/25\n",
      "371/375 [============================>.] - ETA: 0s - loss: 3.3087e-04 - accuracy: 1.0000\n",
      "Epoch 20: val_accuracy did not improve from 0.98525\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 3.3106e-04 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 0.9851 - lr: 2.0000e-04\n",
      "Epoch 21/25\n",
      "373/375 [============================>.] - ETA: 0s - loss: 3.1251e-04 - accuracy: 1.0000\n",
      "Epoch 21: val_accuracy did not improve from 0.98525\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 3.1304e-04 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 0.9851 - lr: 4.0000e-05\n",
      "Epoch 22/25\n",
      "372/375 [============================>.] - ETA: 0s - loss: 3.3621e-04 - accuracy: 1.0000\n",
      "Epoch 22: val_accuracy did not improve from 0.98525\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 3.3608e-04 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 0.9851 - lr: 4.0000e-05\n",
      "Epoch 23/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 3.1708e-04 - accuracy: 1.0000\n",
      "Epoch 23: val_accuracy did not improve from 0.98525\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 3.1708e-04 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 0.9851 - lr: 1.0000e-05\n",
      "Epoch 24/25\n",
      "372/375 [============================>.] - ETA: 0s - loss: 3.1014e-04 - accuracy: 1.0000\n",
      "Epoch 24: val_accuracy did not improve from 0.98525\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 3.0903e-04 - accuracy: 1.0000 - val_loss: 0.0690 - val_accuracy: 0.9850 - lr: 1.0000e-05\n",
      "Epoch 25/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 2.9204e-04 - accuracy: 1.0000\n",
      "Epoch 25: val_accuracy did not improve from 0.98525\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.9204e-04 - accuracy: 1.0000 - val_loss: 0.0694 - val_accuracy: 0.9851 - lr: 1.0000e-05\n",
      "Test loss: 0.06540222465991974\n",
      "Test accuracy: 0.984499990940094\n"
     ]
    }
   ],
   "source": [
    "## Teniendo en cuenta el modelo base añade normalización BatchNorm\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Input, Dropout, BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(784))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "opt=SGD(learning_rate=0.025, momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer=opt,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                                patience=2, min_lr=0.00001)\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "\n",
    "\n",
    "epochs=25\n",
    "batch_size=128\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[reduce_lr,checkpoint])  \n",
    "\n",
    "## Cargar el mejor modelo y evaluarlo con el test set\n",
    "model = keras.models.load_model('best_model.h5')\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aumentado de datos\n",
    "\n",
    "El aumentado de datos consiste en generar nuevos datos de entrenamiento a partir de los datos de entrenamiento originales. De esta forma, se consigue que el modelo sea más robusto y que se generalice mejor a datos que no ha visto durante el entrenamiento.\n",
    "\n",
    "En nuestro caso para los dígitos de la MNIST vamos a realizar un aumento de datos de la siguiente forma:\n",
    "\n",
    "- Rotación aleatoria de la imagen entre -30 y 30 grados.\n",
    "- Traslación aleatoria de la imagen entre -3 y 3 píxeles en horizontal y vertical.\n",
    "- Escalado aleatorio de la imagen entre 0.8 y 1.2.\n",
    "- Inversión aleatoria de la imagen en horizontal y vertical. **NO!!!**\n",
    "\n",
    "El aumentado de datos se ejecuta en CPU y ralentiza el entrenamiento.\n",
    "\n",
    "Normalmente además, se necesitarán más epochs para entrenar el modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.5958 - accuracy: 0.8218\n",
      "Epoch 1: val_accuracy improved from -inf to 0.94075, saving model to best_model.h5\n",
      "375/375 [==============================] - 12s 30ms/step - loss: 0.5952 - accuracy: 0.8220 - val_loss: 0.1945 - val_accuracy: 0.9408 - lr: 0.0250\n",
      "Epoch 2/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.3432 - accuracy: 0.8961\n",
      "Epoch 2: val_accuracy did not improve from 0.94075\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.3432 - accuracy: 0.8961 - val_loss: 0.2327 - val_accuracy: 0.9258 - lr: 0.0250\n",
      "Epoch 3/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.2793 - accuracy: 0.9170\n",
      "Epoch 3: val_accuracy improved from 0.94075 to 0.96742, saving model to best_model.h5\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.2793 - accuracy: 0.9170 - val_loss: 0.1132 - val_accuracy: 0.9674 - lr: 0.0250\n",
      "Epoch 4/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.2417 - accuracy: 0.9279\n",
      "Epoch 4: val_accuracy did not improve from 0.96742\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.2420 - accuracy: 0.9278 - val_loss: 0.1219 - val_accuracy: 0.9635 - lr: 0.0250\n",
      "Epoch 5/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.2252 - accuracy: 0.9320\n",
      "Epoch 5: val_accuracy improved from 0.96742 to 0.97183, saving model to best_model.h5\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.2252 - accuracy: 0.9320 - val_loss: 0.0892 - val_accuracy: 0.9718 - lr: 0.0250\n",
      "Epoch 6/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.2007 - accuracy: 0.9401\n",
      "Epoch 6: val_accuracy did not improve from 0.97183\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.2007 - accuracy: 0.9401 - val_loss: 0.0971 - val_accuracy: 0.9693 - lr: 0.0250\n",
      "Epoch 7/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.1906 - accuracy: 0.9429\n",
      "Epoch 7: val_accuracy did not improve from 0.97183\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.1906 - accuracy: 0.9429 - val_loss: 0.1096 - val_accuracy: 0.9664 - lr: 0.0250\n",
      "Epoch 8/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.1449 - accuracy: 0.9561\n",
      "Epoch 8: val_accuracy improved from 0.97183 to 0.97992, saving model to best_model.h5\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.1449 - accuracy: 0.9561 - val_loss: 0.0640 - val_accuracy: 0.9799 - lr: 0.0050\n",
      "Epoch 9/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.1267 - accuracy: 0.9609\n",
      "Epoch 9: val_accuracy improved from 0.97992 to 0.98100, saving model to best_model.h5\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.1267 - accuracy: 0.9609 - val_loss: 0.0598 - val_accuracy: 0.9810 - lr: 0.0050\n",
      "Epoch 10/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.1163 - accuracy: 0.9644\n",
      "Epoch 10: val_accuracy improved from 0.98100 to 0.98217, saving model to best_model.h5\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.1163 - accuracy: 0.9644 - val_loss: 0.0564 - val_accuracy: 0.9822 - lr: 0.0050\n",
      "Epoch 11/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.1127 - accuracy: 0.9647\n",
      "Epoch 11: val_accuracy improved from 0.98217 to 0.98275, saving model to best_model.h5\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.1127 - accuracy: 0.9647 - val_loss: 0.0551 - val_accuracy: 0.9827 - lr: 0.0050\n",
      "Epoch 12/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.1089 - accuracy: 0.9657\n",
      "Epoch 12: val_accuracy improved from 0.98275 to 0.98300, saving model to best_model.h5\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.1090 - accuracy: 0.9657 - val_loss: 0.0544 - val_accuracy: 0.9830 - lr: 0.0050\n",
      "Epoch 13/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.1036 - accuracy: 0.9683\n",
      "Epoch 13: val_accuracy did not improve from 0.98300\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.1036 - accuracy: 0.9683 - val_loss: 0.0524 - val_accuracy: 0.9829 - lr: 0.0050\n",
      "Epoch 14/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.1018 - accuracy: 0.9679\n",
      "Epoch 14: val_accuracy improved from 0.98300 to 0.98492, saving model to best_model.h5\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.1018 - accuracy: 0.9679 - val_loss: 0.0506 - val_accuracy: 0.9849 - lr: 0.0050\n",
      "Epoch 15/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0984 - accuracy: 0.9688\n",
      "Epoch 15: val_accuracy did not improve from 0.98492\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.0984 - accuracy: 0.9688 - val_loss: 0.0510 - val_accuracy: 0.9837 - lr: 0.0050\n",
      "Epoch 16/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.1012 - accuracy: 0.9696\n",
      "Epoch 16: val_accuracy did not improve from 0.98492\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.1011 - accuracy: 0.9697 - val_loss: 0.0504 - val_accuracy: 0.9839 - lr: 0.0050\n",
      "Epoch 17/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0955 - accuracy: 0.9708\n",
      "Epoch 17: val_accuracy did not improve from 0.98492\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.0955 - accuracy: 0.9708 - val_loss: 0.0492 - val_accuracy: 0.9846 - lr: 0.0050\n",
      "Epoch 18/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0935 - accuracy: 0.9714\n",
      "Epoch 18: val_accuracy improved from 0.98492 to 0.98583, saving model to best_model.h5\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.0935 - accuracy: 0.9714 - val_loss: 0.0475 - val_accuracy: 0.9858 - lr: 0.0050\n",
      "Epoch 19/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0926 - accuracy: 0.9709\n",
      "Epoch 19: val_accuracy improved from 0.98583 to 0.98667, saving model to best_model.h5\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.0927 - accuracy: 0.9709 - val_loss: 0.0467 - val_accuracy: 0.9867 - lr: 0.0050\n",
      "Epoch 20/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0916 - accuracy: 0.9715\n",
      "Epoch 20: val_accuracy did not improve from 0.98667\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.0916 - accuracy: 0.9715 - val_loss: 0.0459 - val_accuracy: 0.9856 - lr: 0.0050\n",
      "Epoch 21/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0938 - accuracy: 0.9710\n",
      "Epoch 21: val_accuracy did not improve from 0.98667\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.0938 - accuracy: 0.9710 - val_loss: 0.0470 - val_accuracy: 0.9860 - lr: 0.0050\n",
      "Epoch 22/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0897 - accuracy: 0.9719\n",
      "Epoch 22: val_accuracy did not improve from 0.98667\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.0897 - accuracy: 0.9719 - val_loss: 0.0469 - val_accuracy: 0.9853 - lr: 0.0050\n",
      "Epoch 23/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0902 - accuracy: 0.9724\n",
      "Epoch 23: val_accuracy did not improve from 0.98667\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.0902 - accuracy: 0.9724 - val_loss: 0.0453 - val_accuracy: 0.9862 - lr: 1.0000e-03\n",
      "Epoch 24/25\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0844 - accuracy: 0.9735\n",
      "Epoch 24: val_accuracy did not improve from 0.98667\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.0844 - accuracy: 0.9735 - val_loss: 0.0448 - val_accuracy: 0.9866 - lr: 1.0000e-03\n",
      "Epoch 25/25\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0841 - accuracy: 0.9740\n",
      "Epoch 25: val_accuracy improved from 0.98667 to 0.98700, saving model to best_model.h5\n",
      "375/375 [==============================] - 11s 29ms/step - loss: 0.0841 - accuracy: 0.9740 - val_loss: 0.0444 - val_accuracy: 0.9870 - lr: 1.0000e-03\n",
      "Test loss: 0.040394965559244156\n",
      "Test accuracy: 0.9873999953269958\n"
     ]
    }
   ],
   "source": [
    "## Implementamos en el ejemplo base el aumentado de datos\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Input, Dropout, BatchNormalization,Reshape\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "## Importante: ImageDataGenerator espera una imagen con 3 canales, necesitamos hacer reshape\n",
    "x_train = x_train.reshape(48000, 28, 28, 1)\n",
    "x_val = x_val.reshape(12000, 28, 28, 1)\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)\n",
    "\n",
    "## Ajustamos el generador de datos\n",
    "datagen.fit(x_train)\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Input, Dropout, BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input((28,28,1)))\n",
    "model.add(Reshape((784,)))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "opt=SGD(learning_rate=0.025, momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer=opt,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=2, min_lr=0.00001)\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "\n",
    "\n",
    "epochs=25\n",
    "batch_size=128\n",
    "## Entrenamos con el generador de datos en lugar de con el dataset\n",
    "history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[reduce_lr,checkpoint])\n",
    "\n",
    "## Cargar el mejor modelo y evaluarlo con el test set\n",
    "model = keras.models.load_model('best_model.h5')\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio:\n",
    "\n",
    "Probar todas las técnicas presentadas para obtener un acierto en **test > 99%**.\n",
    "\n",
    "Se aconseja no malgastar datos de entrenamiento y por lo tanto emplear todo el training set para el entrenamiento. No emplear conjunto de validación y emplear el test set al final para calcular el acierto.\n",
    "\n",
    "A modo de \"trampa\" podríamos ejecutar el fit con los datos de test en validation_data para así monitorizar si llegamos a ese 99%\n",
    "\n",
    "validation_data=(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set (48000, 28, 28, 1)\n",
      "test set (10000, 28, 28)\n",
      "training set (48000, 784)\n",
      "val set (12000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Importar y normalizar datos\n",
    "(x_train2, y_train2), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print('training set', x_train.shape)\n",
    "print('test set', x_test.shape)\n",
    "\n",
    "x_train2 = x_train2.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train2 = x_train2.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalize [0..255]-->[0..1]\n",
    "x_train2 /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "num_classes=10\n",
    "y_train2 = keras.utils.to_categorical(y_train2, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train2, y_train2, test_size=0.2, random_state=42)\n",
    "\n",
    "print('training set', x_train.shape)\n",
    "print('val set', x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.8018 - accuracy: 0.7602\n",
      "Epoch 1: val_accuracy improved from -inf to 0.92280, saving model to best_model.h5\n",
      "469/469 [==============================] - 18s 36ms/step - loss: 0.8013 - accuracy: 0.7604 - val_loss: 0.2484 - val_accuracy: 0.9228 - lr: 0.0100\n",
      "Epoch 2/50\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.4408 - accuracy: 0.8607\n",
      "Epoch 2: val_accuracy improved from 0.92280 to 0.95120, saving model to best_model.h5\n",
      "469/469 [==============================] - 17s 35ms/step - loss: 0.4409 - accuracy: 0.8606 - val_loss: 0.1446 - val_accuracy: 0.9512 - lr: 0.0100\n",
      "Epoch 3/50\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3718 - accuracy: 0.8824 \n",
      "Epoch 3: val_accuracy improved from 0.95120 to 0.96150, saving model to best_model.h5\n",
      "469/469 [==============================] - 4652s 10s/step - loss: 0.3718 - accuracy: 0.8824 - val_loss: 0.1166 - val_accuracy: 0.9615 - lr: 0.0100\n",
      "Epoch 4/50\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.3216 - accuracy: 0.8973\n",
      "Epoch 4: val_accuracy improved from 0.96150 to 0.96580, saving model to best_model.h5\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.3216 - accuracy: 0.8973 - val_loss: 0.1038 - val_accuracy: 0.9658 - lr: 0.0100\n",
      "Epoch 5/50\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.3072 - accuracy: 0.9044\n",
      "Epoch 5: val_accuracy improved from 0.96580 to 0.96700, saving model to best_model.h5\n",
      "469/469 [==============================] - 16s 35ms/step - loss: 0.3071 - accuracy: 0.9044 - val_loss: 0.1027 - val_accuracy: 0.9670 - lr: 0.0100\n",
      "Epoch 6/50\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.2878 - accuracy: 0.9089\n",
      "Epoch 6: val_accuracy improved from 0.96700 to 0.97350, saving model to best_model.h5\n",
      "469/469 [==============================] - 17s 35ms/step - loss: 0.2878 - accuracy: 0.9089 - val_loss: 0.0824 - val_accuracy: 0.9735 - lr: 0.0100\n",
      "Epoch 7/50\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.2841 - accuracy: 0.9116\n",
      "Epoch 7: val_accuracy did not improve from 0.97350\n",
      "469/469 [==============================] - 16s 35ms/step - loss: 0.2839 - accuracy: 0.9117 - val_loss: 0.0893 - val_accuracy: 0.9703 - lr: 0.0100\n",
      "Epoch 8/50\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.2734 - accuracy: 0.9151\n",
      "Epoch 8: val_accuracy did not improve from 0.97350\n",
      "469/469 [==============================] - 16s 35ms/step - loss: 0.2734 - accuracy: 0.9151 - val_loss: 0.0988 - val_accuracy: 0.9686 - lr: 0.0100\n",
      "Epoch 9/50\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.2102 - accuracy: 0.9340\n",
      "Epoch 9: val_accuracy improved from 0.97350 to 0.98250, saving model to best_model.h5\n",
      "469/469 [==============================] - 17s 35ms/step - loss: 0.2102 - accuracy: 0.9340 - val_loss: 0.0542 - val_accuracy: 0.9825 - lr: 0.0020\n",
      "Epoch 10/50\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1877 - accuracy: 0.9401\n",
      "Epoch 10: val_accuracy improved from 0.98250 to 0.98300, saving model to best_model.h5\n",
      "469/469 [==============================] - 16s 35ms/step - loss: 0.1877 - accuracy: 0.9401 - val_loss: 0.0526 - val_accuracy: 0.9830 - lr: 0.0020\n",
      "Epoch 11/50\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.1796 - accuracy: 0.9435\n",
      "Epoch 11: val_accuracy did not improve from 0.98300\n",
      "469/469 [==============================] - 16s 35ms/step - loss: 0.1795 - accuracy: 0.9435 - val_loss: 0.0534 - val_accuracy: 0.9830 - lr: 0.0020\n",
      "Epoch 12/50\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1709 - accuracy: 0.9462\n",
      "Epoch 12: val_accuracy improved from 0.98300 to 0.98340, saving model to best_model.h5\n",
      "469/469 [==============================] - 17s 35ms/step - loss: 0.1709 - accuracy: 0.9462 - val_loss: 0.0491 - val_accuracy: 0.9834 - lr: 0.0020\n",
      "Epoch 13/50\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.1643 - accuracy: 0.9478\n",
      "Epoch 13: val_accuracy improved from 0.98340 to 0.98430, saving model to best_model.h5\n",
      "469/469 [==============================] - 17s 35ms/step - loss: 0.1643 - accuracy: 0.9479 - val_loss: 0.0472 - val_accuracy: 0.9843 - lr: 0.0020\n",
      "Epoch 14/50\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1622 - accuracy: 0.9493\n",
      "Epoch 14: val_accuracy improved from 0.98430 to 0.98630, saving model to best_model.h5\n",
      "469/469 [==============================] - 17s 35ms/step - loss: 0.1622 - accuracy: 0.9493 - val_loss: 0.0444 - val_accuracy: 0.9863 - lr: 0.0020\n",
      "Epoch 15/50\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.1578 - accuracy: 0.9511\n",
      "Epoch 15: val_accuracy did not improve from 0.98630\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1578 - accuracy: 0.9511 - val_loss: 0.0446 - val_accuracy: 0.9860 - lr: 0.0020\n",
      "Epoch 16/50\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.1529 - accuracy: 0.9520\n",
      "Epoch 16: val_accuracy improved from 0.98630 to 0.98650, saving model to best_model.h5\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1528 - accuracy: 0.9520 - val_loss: 0.0436 - val_accuracy: 0.9865 - lr: 0.0020\n",
      "Epoch 17/50\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.1520 - accuracy: 0.9527\n",
      "Epoch 17: val_accuracy did not improve from 0.98650\n",
      "469/469 [==============================] - 17s 35ms/step - loss: 0.1521 - accuracy: 0.9527 - val_loss: 0.0443 - val_accuracy: 0.9860 - lr: 0.0020\n",
      "Epoch 18/50\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1478 - accuracy: 0.9535\n",
      "Epoch 18: val_accuracy improved from 0.98650 to 0.98680, saving model to best_model.h5\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1478 - accuracy: 0.9535 - val_loss: 0.0412 - val_accuracy: 0.9868 - lr: 0.0020\n",
      "Epoch 19/50\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.1456 - accuracy: 0.9537\n",
      "Epoch 19: val_accuracy did not improve from 0.98680\n",
      "469/469 [==============================] - 17s 35ms/step - loss: 0.1455 - accuracy: 0.9537 - val_loss: 0.0415 - val_accuracy: 0.9866 - lr: 0.0020\n",
      "Epoch 20/50\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.1411 - accuracy: 0.9553\n",
      "Epoch 20: val_accuracy improved from 0.98680 to 0.98710, saving model to best_model.h5\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1411 - accuracy: 0.9553 - val_loss: 0.0409 - val_accuracy: 0.9871 - lr: 0.0020\n",
      "Epoch 21/50\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.1390 - accuracy: 0.9559\n",
      "Epoch 21: val_accuracy did not improve from 0.98710\n",
      "469/469 [==============================] - 17s 35ms/step - loss: 0.1388 - accuracy: 0.9560 - val_loss: 0.0398 - val_accuracy: 0.9864 - lr: 0.0020\n",
      "Epoch 22/50\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.1388 - accuracy: 0.9561\n",
      "Epoch 22: val_accuracy did not improve from 0.98710\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1387 - accuracy: 0.9562 - val_loss: 0.0371 - val_accuracy: 0.9868 - lr: 0.0020\n",
      "Epoch 23/50\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1361 - accuracy: 0.9574\n",
      "Epoch 23: val_accuracy did not improve from 0.98710\n",
      "469/469 [==============================] - 17s 35ms/step - loss: 0.1361 - accuracy: 0.9574 - val_loss: 0.0377 - val_accuracy: 0.9868 - lr: 0.0020\n",
      "Epoch 24/50\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1376 - accuracy: 0.9574\n",
      "Epoch 24: val_accuracy did not improve from 0.98710\n",
      "469/469 [==============================] - 17s 35ms/step - loss: 0.1376 - accuracy: 0.9574 - val_loss: 0.0390 - val_accuracy: 0.9861 - lr: 0.0020\n",
      "Epoch 25/50\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1252 - accuracy: 0.9610\n",
      "Epoch 25: val_accuracy improved from 0.98710 to 0.98810, saving model to best_model.h5\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1252 - accuracy: 0.9610 - val_loss: 0.0344 - val_accuracy: 0.9881 - lr: 4.0000e-04\n",
      "Epoch 26/50\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1214 - accuracy: 0.9621\n",
      "Epoch 26: val_accuracy improved from 0.98810 to 0.98860, saving model to best_model.h5\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1214 - accuracy: 0.9621 - val_loss: 0.0335 - val_accuracy: 0.9886 - lr: 4.0000e-04\n",
      "Epoch 27/50\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1172 - accuracy: 0.9635\n",
      "Epoch 27: val_accuracy did not improve from 0.98860\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1172 - accuracy: 0.9635 - val_loss: 0.0328 - val_accuracy: 0.9883 - lr: 4.0000e-04\n",
      "Epoch 28/50\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1170 - accuracy: 0.9629\n",
      "Epoch 28: val_accuracy did not improve from 0.98860\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1170 - accuracy: 0.9629 - val_loss: 0.0333 - val_accuracy: 0.9886 - lr: 4.0000e-04\n",
      "Epoch 29/50\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.1136 - accuracy: 0.9648\n",
      "Epoch 29: val_accuracy did not improve from 0.98860\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1138 - accuracy: 0.9648 - val_loss: 0.0328 - val_accuracy: 0.9885 - lr: 4.0000e-04\n",
      "Epoch 30/50\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.1129 - accuracy: 0.9645\n",
      "Epoch 30: val_accuracy did not improve from 0.98860\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1130 - accuracy: 0.9645 - val_loss: 0.0321 - val_accuracy: 0.9884 - lr: 8.0000e-05\n",
      "Epoch 31/50\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1148 - accuracy: 0.9640\n",
      "Epoch 31: val_accuracy did not improve from 0.98860\n",
      "469/469 [==============================] - 17s 37ms/step - loss: 0.1148 - accuracy: 0.9640 - val_loss: 0.0322 - val_accuracy: 0.9884 - lr: 8.0000e-05\n",
      "Epoch 32/50\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.1144 - accuracy: 0.9644\n",
      "Epoch 32: val_accuracy improved from 0.98860 to 0.98880, saving model to best_model.h5\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1144 - accuracy: 0.9644 - val_loss: 0.0318 - val_accuracy: 0.9888 - lr: 8.0000e-05\n",
      "Epoch 33/50\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1148 - accuracy: 0.9629\n",
      "Epoch 33: val_accuracy did not improve from 0.98880\n",
      "469/469 [==============================] - 17s 37ms/step - loss: 0.1148 - accuracy: 0.9629 - val_loss: 0.0315 - val_accuracy: 0.9888 - lr: 8.0000e-05\n",
      "Epoch 34/50\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.1109 - accuracy: 0.9645\n",
      "Epoch 34: val_accuracy did not improve from 0.98880\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1111 - accuracy: 0.9644 - val_loss: 0.0316 - val_accuracy: 0.9888 - lr: 8.0000e-05\n",
      "Epoch 35/50\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1140 - accuracy: 0.9635\n",
      "Epoch 35: val_accuracy improved from 0.98880 to 0.98910, saving model to best_model.h5\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1140 - accuracy: 0.9635 - val_loss: 0.0313 - val_accuracy: 0.9891 - lr: 8.0000e-05\n",
      "Epoch 36/50\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.1070 - accuracy: 0.9659\n",
      "Epoch 36: val_accuracy did not improve from 0.98910\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1069 - accuracy: 0.9659 - val_loss: 0.0312 - val_accuracy: 0.9891 - lr: 8.0000e-05\n",
      "Epoch 37/50\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1107 - accuracy: 0.9644\n",
      "Epoch 37: val_accuracy did not improve from 0.98910\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1107 - accuracy: 0.9644 - val_loss: 0.0314 - val_accuracy: 0.9889 - lr: 8.0000e-05\n",
      "Epoch 38/50\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.1102 - accuracy: 0.9649\n",
      "Epoch 38: val_accuracy did not improve from 0.98910\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1102 - accuracy: 0.9650 - val_loss: 0.0312 - val_accuracy: 0.9889 - lr: 8.0000e-05\n",
      "Epoch 39/50\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.1077 - accuracy: 0.9666\n",
      "Epoch 39: val_accuracy did not improve from 0.98910\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1077 - accuracy: 0.9666 - val_loss: 0.0311 - val_accuracy: 0.9888 - lr: 1.6000e-05\n",
      "Epoch 40/50\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1071 - accuracy: 0.9666\n",
      "Epoch 40: val_accuracy did not improve from 0.98910\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1071 - accuracy: 0.9666 - val_loss: 0.0311 - val_accuracy: 0.9885 - lr: 1.6000e-05\n",
      "Epoch 41/50\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1066 - accuracy: 0.9662\n",
      "Epoch 41: val_accuracy did not improve from 0.98910\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1066 - accuracy: 0.9662 - val_loss: 0.0312 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
      "Epoch 42/50\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.1091 - accuracy: 0.9652\n",
      "Epoch 42: val_accuracy did not improve from 0.98910\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1093 - accuracy: 0.9652 - val_loss: 0.0310 - val_accuracy: 0.9889 - lr: 1.0000e-05\n",
      "Epoch 43/50\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1086 - accuracy: 0.9659\n",
      "Epoch 43: val_accuracy did not improve from 0.98910\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1086 - accuracy: 0.9659 - val_loss: 0.0311 - val_accuracy: 0.9887 - lr: 1.0000e-05\n",
      "Epoch 44/50\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.1094 - accuracy: 0.9650\n",
      "Epoch 44: val_accuracy did not improve from 0.98910\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1094 - accuracy: 0.9650 - val_loss: 0.0311 - val_accuracy: 0.9888 - lr: 1.0000e-05\n",
      "Epoch 45/50\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1080 - accuracy: 0.9657\n",
      "Epoch 45: val_accuracy did not improve from 0.98910\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1080 - accuracy: 0.9657 - val_loss: 0.0311 - val_accuracy: 0.9887 - lr: 1.0000e-05\n",
      "Epoch 46/50\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.1069 - accuracy: 0.9658\n",
      "Epoch 46: val_accuracy did not improve from 0.98910\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1070 - accuracy: 0.9657 - val_loss: 0.0311 - val_accuracy: 0.9885 - lr: 1.0000e-05\n",
      "Epoch 47/50\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.1077 - accuracy: 0.9661\n",
      "Epoch 47: val_accuracy did not improve from 0.98910\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1077 - accuracy: 0.9661 - val_loss: 0.0312 - val_accuracy: 0.9886 - lr: 1.0000e-05\n",
      "Epoch 48/50\n",
      "468/469 [============================>.] - ETA: 0s - loss: 0.1112 - accuracy: 0.9653\n",
      "Epoch 48: val_accuracy did not improve from 0.98910\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1111 - accuracy: 0.9654 - val_loss: 0.0313 - val_accuracy: 0.9886 - lr: 1.0000e-05\n",
      "Epoch 49/50\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1069 - accuracy: 0.9658\n",
      "Epoch 49: val_accuracy did not improve from 0.98910\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1069 - accuracy: 0.9658 - val_loss: 0.0310 - val_accuracy: 0.9888 - lr: 1.0000e-05\n",
      "Epoch 50/50\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.9663\n",
      "Epoch 50: val_accuracy did not improve from 0.98910\n",
      "469/469 [==============================] - 17s 36ms/step - loss: 0.1097 - accuracy: 0.9663 - val_loss: 0.0313 - val_accuracy: 0.9888 - lr: 1.0000e-05\n",
      "Test loss: 0.031328361481428146\n",
      "Test accuracy: 0.9890999794006348\n"
     ]
    }
   ],
   "source": [
    "## Implementamos en el ejemplo base el aumentado de datos\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Input, Dropout, BatchNormalization,Reshape\n",
    "from keras.optimizers import SGD,Adam,AdamW\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "## Importante: ImageDataGenerator espera una imagen con 3 canales, necesitamos hacer reshape\n",
    "x_train2 = x_train2.reshape(60000, 28, 28, 1)\n",
    "#x_val = x_val.reshape(12000, 28, 28, 1)\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)\n",
    "\n",
    "## Ajustamos el generador de datos\n",
    "datagen.fit(x_train2)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input((28,28,1)))\n",
    "model.add(Reshape((784,)))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#opt=SGD(learning_rate=0.025, momentum=0.9)\n",
    "# lr = 0.01\n",
    "opt = AdamW(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer=opt,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=2, min_lr=0.00001)\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "#earlystopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3)\n",
    "\n",
    "epochs=50\n",
    "batch_size=128\n",
    "## Entrenamos con el generador de datos en lugar de con el dataset\n",
    "history = model.fit(datagen.flow(x_train2, y_train2, batch_size=batch_size),\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[reduce_lr,checkpoint])\n",
    "\n",
    "## Cargar el mejor modelo y evaluarlo con el test set\n",
    "model = keras.models.load_model('best_model.h5')\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

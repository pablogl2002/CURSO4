{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variaciones sobre el modelo inicial \n",
    "\n",
    "Vamos a implementar alguna modificación sobre el modelo inicial propuesto en la primera sesión.\n",
    "\n",
    "Para empezar vamos a definir un conjunto de validación. Con este conjunto de calidación extraído del propio conjunto de entrenamiento estimaremos los mejores parámetros. Dejaremos el conjunto de test sólo para estimar el acierto final con estos mejores parámetros.\n",
    "\n",
    "Primero leemos los datos y normalizamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set (60000, 28, 28)\n",
      "test set (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print('training set', x_train.shape)\n",
    "print('test set', x_test.shape)\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalize [0..255]-->[0..1]\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "num_classes=10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partición training/validación\n",
    "\n",
    "Nos quedaremos con un 80% de los datos para entrenar y un 20% para validar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set (48000, 784)\n",
      "val set (12000, 784)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train2, x_val, y_train2, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print('training set', x_train2.shape)\n",
    "print('val set', x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentación con conjunto de validación\n",
    "\n",
    "Cualquier parámetro a modificar en nuestro modelo debería ser probado sobre el conjunto de validación y escoger aquel que produjera el mejor resultado para probar ese (y sólo ese) sobre el conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5435 - accuracy: 0.8495 - val_loss: 0.3122 - val_accuracy: 0.9116\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2821 - accuracy: 0.9189 - val_loss: 0.2495 - val_accuracy: 0.9277\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2309 - accuracy: 0.9352 - val_loss: 0.2155 - val_accuracy: 0.9392\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1977 - accuracy: 0.9444 - val_loss: 0.1908 - val_accuracy: 0.9455\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1729 - accuracy: 0.9506 - val_loss: 0.1732 - val_accuracy: 0.9525\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5187 - accuracy: 0.8567 - val_loss: 0.3007 - val_accuracy: 0.9156\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2725 - accuracy: 0.9227 - val_loss: 0.2439 - val_accuracy: 0.9317\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2235 - accuracy: 0.9369 - val_loss: 0.2072 - val_accuracy: 0.9432\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1898 - accuracy: 0.9466 - val_loss: 0.1829 - val_accuracy: 0.9477\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1657 - accuracy: 0.9535 - val_loss: 0.1630 - val_accuracy: 0.9542\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5019 - accuracy: 0.8665 - val_loss: 0.2966 - val_accuracy: 0.9165\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2636 - accuracy: 0.9263 - val_loss: 0.2364 - val_accuracy: 0.9362\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2151 - accuracy: 0.9395 - val_loss: 0.2023 - val_accuracy: 0.9434\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1824 - accuracy: 0.9493 - val_loss: 0.1771 - val_accuracy: 0.9503\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1582 - accuracy: 0.9555 - val_loss: 0.1596 - val_accuracy: 0.9557\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4897 - accuracy: 0.8686 - val_loss: 0.2982 - val_accuracy: 0.9143\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2613 - accuracy: 0.9273 - val_loss: 0.2305 - val_accuracy: 0.9356\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2101 - accuracy: 0.9421 - val_loss: 0.1973 - val_accuracy: 0.9468\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1772 - accuracy: 0.9509 - val_loss: 0.1718 - val_accuracy: 0.9528\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1524 - accuracy: 0.9581 - val_loss: 0.1558 - val_accuracy: 0.9574\n",
      "=============================\n",
      "Best acc 0.9574166536331177\n",
      "Best hidden dim 1024\n",
      "=============================\n",
      "Epoch 1/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.4518 - accuracy: 0.8768 - val_loss: 0.2656 - val_accuracy: 0.9281\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2393 - accuracy: 0.9330 - val_loss: 0.2052 - val_accuracy: 0.9426\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1895 - accuracy: 0.9473 - val_loss: 0.1689 - val_accuracy: 0.9522\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1572 - accuracy: 0.9565 - val_loss: 0.1458 - val_accuracy: 0.9596\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1346 - accuracy: 0.9638 - val_loss: 0.1285 - val_accuracy: 0.9638\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "batch_size=128\n",
    "epochs=5  \n",
    "\n",
    "hdim=[128,256,512,1024]\n",
    "best_acc=0.0\n",
    "for h in hdim:\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(784))\n",
    "    model.add(Dense(h, activation='relu')) # <-- repetir esta línea tantas veces como número de capas ocultas se quiera\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    sgd=SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    " \n",
    "\n",
    "    history = model.fit(x_train2, y_train2,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val, y_val)) ## <--- OJO validation set\n",
    "    \n",
    "    if history.history['val_accuracy'][-1]>best_acc:\n",
    "        best_acc=history.history['val_accuracy'][-1]\n",
    "        besth=h\n",
    "\n",
    "print(\"=============================\")\n",
    "print(\"Best acc\",best_acc)\n",
    "print(\"Best hidden dim\",besth)\n",
    "print(\"=============================\")\n",
    "\n",
    "\n",
    "## PROBAR EL MEJOR CON TEST\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(784))\n",
    "model.add(Dense(besth, activation='relu'))  \n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "sgd=SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, # <--- aquí podríamos concatenar trainin+valid para no malgastar datos\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EARLY STOPPING\n",
    "\n",
    "De la multitud de parámetros a decidir en la definición y entrenamiento de las redes neuronales hay uno que podríamos automatizar. Es el número de epochs a emplear. Dado que tenemos un conjunto de validación vamos a emplearlo para monitorizar cómo evoluciona la convergencia. Si en algún momento el descenso por gradiente parece haber alcanzado una zona de meseta sobre dicho conjunto de validación podremos detener el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4935 - accuracy: 0.8659 - val_loss: 0.2941 - val_accuracy: 0.9177\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2631 - accuracy: 0.9257 - val_loss: 0.2329 - val_accuracy: 0.9367\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2130 - accuracy: 0.9409 - val_loss: 0.1992 - val_accuracy: 0.9448\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1793 - accuracy: 0.9502 - val_loss: 0.1731 - val_accuracy: 0.9518\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1556 - accuracy: 0.9563 - val_loss: 0.1544 - val_accuracy: 0.9571\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1361 - accuracy: 0.9627 - val_loss: 0.1411 - val_accuracy: 0.9618\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1211 - accuracy: 0.9668 - val_loss: 0.1305 - val_accuracy: 0.9636\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1089 - accuracy: 0.9711 - val_loss: 0.1219 - val_accuracy: 0.9661\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0989 - accuracy: 0.9737 - val_loss: 0.1163 - val_accuracy: 0.9672\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0899 - accuracy: 0.9763 - val_loss: 0.1100 - val_accuracy: 0.9688\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0824 - accuracy: 0.9783 - val_loss: 0.1034 - val_accuracy: 0.9707\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0759 - accuracy: 0.9805 - val_loss: 0.1014 - val_accuracy: 0.9707\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0704 - accuracy: 0.9824 - val_loss: 0.0975 - val_accuracy: 0.9716\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0654 - accuracy: 0.9835 - val_loss: 0.0952 - val_accuracy: 0.9723\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Input(784))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "sgd=SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3) ## También podría ser 'loss' sin necesitar un conjunto de validación\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs=100  ## No nos preocupemos, el fit acabará antes por el early_stopping\n",
    "history = model.fit(x_train2, y_train2,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[callback])  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Ejercicio**:\n",
    "\n",
    "Entrenar una red neuronal MLP para el problema MNIST. Los valores que se quieren probar son los siguientes:\n",
    "\n",
    "-   Número de capas ocultas [1,2,3]\n",
    "-   Dimensión de las capas ocultas [512,1024]\n",
    "-   Learning rate [0.025, 0.01]\n",
    "-   Batch_size [128]\n",
    "-   Epochs con early_stopping\n",
    "\n",
    "Obtener la mejor combinación con el conjunto de validación y probarla finalmente sobre el conjunto de test.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.3842 - accuracy: 0.8898 - val_loss: 0.2282 - val_accuracy: 0.9359\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1880 - accuracy: 0.9471 - val_loss: 0.1622 - val_accuracy: 0.9553\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1368 - accuracy: 0.9608 - val_loss: 0.1328 - val_accuracy: 0.9629\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1077 - accuracy: 0.9700 - val_loss: 0.1163 - val_accuracy: 0.9683\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0893 - accuracy: 0.9751 - val_loss: 0.1069 - val_accuracy: 0.9701\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0741 - accuracy: 0.9801 - val_loss: 0.0939 - val_accuracy: 0.9723\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0636 - accuracy: 0.9825 - val_loss: 0.0907 - val_accuracy: 0.9722\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.0550 - accuracy: 0.9854 - val_loss: 0.0825 - val_accuracy: 0.9767\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0476 - accuracy: 0.9880 - val_loss: 0.0802 - val_accuracy: 0.9764\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0412 - accuracy: 0.9897 - val_loss: 0.0773 - val_accuracy: 0.9763\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0365 - accuracy: 0.9911 - val_loss: 0.0753 - val_accuracy: 0.9772\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5059 - accuracy: 0.8641 - val_loss: 0.3005 - val_accuracy: 0.9148\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2675 - accuracy: 0.9244 - val_loss: 0.2388 - val_accuracy: 0.9340\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2168 - accuracy: 0.9393 - val_loss: 0.2016 - val_accuracy: 0.9453\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1836 - accuracy: 0.9490 - val_loss: 0.1810 - val_accuracy: 0.9486\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1597 - accuracy: 0.9557 - val_loss: 0.1671 - val_accuracy: 0.9530\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1412 - accuracy: 0.9611 - val_loss: 0.1468 - val_accuracy: 0.9584\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1257 - accuracy: 0.9656 - val_loss: 0.1364 - val_accuracy: 0.9619\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1142 - accuracy: 0.9690 - val_loss: 0.1272 - val_accuracy: 0.9632\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1037 - accuracy: 0.9721 - val_loss: 0.1199 - val_accuracy: 0.9655\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0950 - accuracy: 0.9740 - val_loss: 0.1132 - val_accuracy: 0.9681\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0878 - accuracy: 0.9767 - val_loss: 0.1079 - val_accuracy: 0.9684\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0810 - accuracy: 0.9787 - val_loss: 0.1038 - val_accuracy: 0.9707\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0751 - accuracy: 0.9808 - val_loss: 0.1013 - val_accuracy: 0.9693\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0698 - accuracy: 0.9816 - val_loss: 0.0974 - val_accuracy: 0.9718\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0654 - accuracy: 0.9830 - val_loss: 0.0942 - val_accuracy: 0.9735\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0612 - accuracy: 0.9839 - val_loss: 0.0913 - val_accuracy: 0.9733\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0574 - accuracy: 0.9854 - val_loss: 0.0922 - val_accuracy: 0.9731\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.3569 - accuracy: 0.8951 - val_loss: 0.1960 - val_accuracy: 0.9437\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1396 - accuracy: 0.9596 - val_loss: 0.1239 - val_accuracy: 0.9632\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0956 - accuracy: 0.9721 - val_loss: 0.0986 - val_accuracy: 0.9709\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0710 - accuracy: 0.9791 - val_loss: 0.0880 - val_accuracy: 0.9728\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0536 - accuracy: 0.9846 - val_loss: 0.0802 - val_accuracy: 0.9755\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0411 - accuracy: 0.9882 - val_loss: 0.0785 - val_accuracy: 0.9769\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0320 - accuracy: 0.9912 - val_loss: 0.0749 - val_accuracy: 0.9772\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0250 - accuracy: 0.9934 - val_loss: 0.0715 - val_accuracy: 0.9798\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0193 - accuracy: 0.9952 - val_loss: 0.0736 - val_accuracy: 0.9785\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0137 - accuracy: 0.9975 - val_loss: 0.0728 - val_accuracy: 0.9796\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4931 - accuracy: 0.8619 - val_loss: 0.2674 - val_accuracy: 0.9233\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2169 - accuracy: 0.9380 - val_loss: 0.1870 - val_accuracy: 0.9463\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1599 - accuracy: 0.9543 - val_loss: 0.1521 - val_accuracy: 0.9559\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1265 - accuracy: 0.9639 - val_loss: 0.1292 - val_accuracy: 0.9628\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1042 - accuracy: 0.9705 - val_loss: 0.1146 - val_accuracy: 0.9668\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0875 - accuracy: 0.9754 - val_loss: 0.1063 - val_accuracy: 0.9681\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0747 - accuracy: 0.9788 - val_loss: 0.0996 - val_accuracy: 0.9702\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0638 - accuracy: 0.9817 - val_loss: 0.0918 - val_accuracy: 0.9728\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0548 - accuracy: 0.9848 - val_loss: 0.0871 - val_accuracy: 0.9735\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0473 - accuracy: 0.9870 - val_loss: 0.0845 - val_accuracy: 0.9743\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0410 - accuracy: 0.9892 - val_loss: 0.0805 - val_accuracy: 0.9753\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0356 - accuracy: 0.9909 - val_loss: 0.0795 - val_accuracy: 0.9767\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.3618 - accuracy: 0.8961 - val_loss: 0.1617 - val_accuracy: 0.9515\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.1270 - accuracy: 0.9616 - val_loss: 0.1184 - val_accuracy: 0.9647\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0821 - accuracy: 0.9746 - val_loss: 0.0843 - val_accuracy: 0.9745\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0575 - accuracy: 0.9826 - val_loss: 0.0875 - val_accuracy: 0.9739\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0399 - accuracy: 0.9875 - val_loss: 0.0760 - val_accuracy: 0.9777\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0310 - accuracy: 0.9908 - val_loss: 0.0767 - val_accuracy: 0.9770\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.4866 - accuracy: 0.8625 - val_loss: 0.2192 - val_accuracy: 0.9361\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1872 - accuracy: 0.9455 - val_loss: 0.1596 - val_accuracy: 0.9548\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1327 - accuracy: 0.9613 - val_loss: 0.1266 - val_accuracy: 0.9632\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.1019 - accuracy: 0.9701 - val_loss: 0.1043 - val_accuracy: 0.9688\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0806 - accuracy: 0.9764 - val_loss: 0.1049 - val_accuracy: 0.9698\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.0649 - accuracy: 0.9810 - val_loss: 0.0880 - val_accuracy: 0.9732\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0518 - accuracy: 0.9849 - val_loss: 0.0855 - val_accuracy: 0.9752\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0418 - accuracy: 0.9883 - val_loss: 0.0771 - val_accuracy: 0.9769\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.0337 - accuracy: 0.9907 - val_loss: 0.0788 - val_accuracy: 0.9762\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0272 - accuracy: 0.9929 - val_loss: 0.0758 - val_accuracy: 0.9768\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.0233 - accuracy: 0.9937 - val_loss: 0.0809 - val_accuracy: 0.9762\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.3750 - accuracy: 0.8939 - val_loss: 0.2291 - val_accuracy: 0.9369\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1837 - accuracy: 0.9483 - val_loss: 0.1577 - val_accuracy: 0.9552\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1311 - accuracy: 0.9638 - val_loss: 0.1319 - val_accuracy: 0.9638\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1028 - accuracy: 0.9721 - val_loss: 0.1188 - val_accuracy: 0.9643\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0844 - accuracy: 0.9761 - val_loss: 0.1012 - val_accuracy: 0.9697\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 0.0704 - accuracy: 0.9808 - val_loss: 0.0966 - val_accuracy: 0.9715\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0599 - accuracy: 0.9835 - val_loss: 0.0864 - val_accuracy: 0.9747\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0515 - accuracy: 0.9862 - val_loss: 0.0813 - val_accuracy: 0.9757\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0441 - accuracy: 0.9891 - val_loss: 0.0791 - val_accuracy: 0.9776\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0391 - accuracy: 0.9901 - val_loss: 0.0786 - val_accuracy: 0.9754\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.4846 - accuracy: 0.8692 - val_loss: 0.2896 - val_accuracy: 0.9183\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.2573 - accuracy: 0.9282 - val_loss: 0.2330 - val_accuracy: 0.9362\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.2086 - accuracy: 0.9419 - val_loss: 0.1996 - val_accuracy: 0.9439\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1761 - accuracy: 0.9502 - val_loss: 0.1746 - val_accuracy: 0.9511\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.1530 - accuracy: 0.9574 - val_loss: 0.1583 - val_accuracy: 0.9555\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1346 - accuracy: 0.9627 - val_loss: 0.1416 - val_accuracy: 0.9609\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1198 - accuracy: 0.9670 - val_loss: 0.1295 - val_accuracy: 0.9632\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.1078 - accuracy: 0.9707 - val_loss: 0.1226 - val_accuracy: 0.9652\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0976 - accuracy: 0.9743 - val_loss: 0.1162 - val_accuracy: 0.9673\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0892 - accuracy: 0.9764 - val_loss: 0.1090 - val_accuracy: 0.9688\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0819 - accuracy: 0.9792 - val_loss: 0.1044 - val_accuracy: 0.9695\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0751 - accuracy: 0.9806 - val_loss: 0.0990 - val_accuracy: 0.9712\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0701 - accuracy: 0.9813 - val_loss: 0.0963 - val_accuracy: 0.9712\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0649 - accuracy: 0.9835 - val_loss: 0.0934 - val_accuracy: 0.9728\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0601 - accuracy: 0.9852 - val_loss: 0.0901 - val_accuracy: 0.9728\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0563 - accuracy: 0.9861 - val_loss: 0.0895 - val_accuracy: 0.9738\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0528 - accuracy: 0.9866 - val_loss: 0.0865 - val_accuracy: 0.9740\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.3463 - accuracy: 0.8994 - val_loss: 0.1703 - val_accuracy: 0.9512\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.1355 - accuracy: 0.9602 - val_loss: 0.1160 - val_accuracy: 0.9678\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0901 - accuracy: 0.9747 - val_loss: 0.0938 - val_accuracy: 0.9718\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0643 - accuracy: 0.9818 - val_loss: 0.0996 - val_accuracy: 0.9688\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0493 - accuracy: 0.9859 - val_loss: 0.0755 - val_accuracy: 0.9777\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0358 - accuracy: 0.9898 - val_loss: 0.0741 - val_accuracy: 0.9785\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0272 - accuracy: 0.9930 - val_loss: 0.0740 - val_accuracy: 0.9786\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0200 - accuracy: 0.9953 - val_loss: 0.0702 - val_accuracy: 0.9793\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.4631 - accuracy: 0.8727 - val_loss: 0.2554 - val_accuracy: 0.9274\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2112 - accuracy: 0.9392 - val_loss: 0.1951 - val_accuracy: 0.9420\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.1559 - accuracy: 0.9556 - val_loss: 0.1478 - val_accuracy: 0.9588\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.1222 - accuracy: 0.9659 - val_loss: 0.1283 - val_accuracy: 0.9631\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.1002 - accuracy: 0.9717 - val_loss: 0.1146 - val_accuracy: 0.9671\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0834 - accuracy: 0.9769 - val_loss: 0.1062 - val_accuracy: 0.9693\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0700 - accuracy: 0.9808 - val_loss: 0.0939 - val_accuracy: 0.9720\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0608 - accuracy: 0.9830 - val_loss: 0.0874 - val_accuracy: 0.9741\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0511 - accuracy: 0.9866 - val_loss: 0.0845 - val_accuracy: 0.9744\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0442 - accuracy: 0.9886 - val_loss: 0.0812 - val_accuracy: 0.9767\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0377 - accuracy: 0.9910 - val_loss: 0.0853 - val_accuracy: 0.9742\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0329 - accuracy: 0.9921 - val_loss: 0.0749 - val_accuracy: 0.9771\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0280 - accuracy: 0.9937 - val_loss: 0.0738 - val_accuracy: 0.9776\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3463 - accuracy: 0.8997 - val_loss: 0.1430 - val_accuracy: 0.9583\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.1165 - accuracy: 0.9653 - val_loss: 0.1043 - val_accuracy: 0.9680\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.0735 - accuracy: 0.9774 - val_loss: 0.0905 - val_accuracy: 0.9726\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.0500 - accuracy: 0.9850 - val_loss: 0.0860 - val_accuracy: 0.9734\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.0340 - accuracy: 0.9899 - val_loss: 0.0830 - val_accuracy: 0.9757\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.0226 - accuracy: 0.9934 - val_loss: 0.0721 - val_accuracy: 0.9790\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.0167 - accuracy: 0.9959 - val_loss: 0.0728 - val_accuracy: 0.9795\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.0896 - val_accuracy: 0.9760\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 0.0679 - val_accuracy: 0.9827\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4583 - accuracy: 0.8728 - val_loss: 0.2100 - val_accuracy: 0.9402\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.1799 - accuracy: 0.9485 - val_loss: 0.1531 - val_accuracy: 0.9541\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.1261 - accuracy: 0.9629 - val_loss: 0.1235 - val_accuracy: 0.9642\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.0930 - accuracy: 0.9731 - val_loss: 0.1369 - val_accuracy: 0.9572\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.0728 - accuracy: 0.9793 - val_loss: 0.0915 - val_accuracy: 0.9728\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.0573 - accuracy: 0.9837 - val_loss: 0.0853 - val_accuracy: 0.9739\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.0445 - accuracy: 0.9875 - val_loss: 0.0977 - val_accuracy: 0.9707\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.0354 - accuracy: 0.9903 - val_loss: 0.0800 - val_accuracy: 0.9753\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.0277 - accuracy: 0.9928 - val_loss: 0.0776 - val_accuracy: 0.9763\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.0214 - accuracy: 0.9949 - val_loss: 0.0718 - val_accuracy: 0.9772\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.0174 - accuracy: 0.9960 - val_loss: 0.0742 - val_accuracy: 0.9778\n",
      "=============================\n",
      "Best acc 0.9826666712760925\n",
      "Best hden 3\n",
      "Best hdim 1024\n",
      "Best learning rate 0.025\n",
      "=============================\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "for hdim in [512, 1024]:\n",
    "    for hden in [1,2,3]:\n",
    "        for l_rate in [0.025, 0.01]:\n",
    "            model = Sequential()\n",
    "            model.add(Input(784))\n",
    "            for i in range(hden):\n",
    "                model.add(Dense(hdim, activation='relu'))\n",
    "            model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "            \n",
    "            sgd=SGD(learning_rate=l_rate, momentum=0.9)\n",
    "\n",
    "            callback = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3) ## También podría ser 'loss' sin necesitar un conjunto de validación\n",
    "\n",
    "            model.compile(loss='categorical_crossentropy',\n",
    "                        optimizer=sgd,\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "            epochs=100  ## No nos preocupemos, el fit acabará antes por el early_stopping\n",
    "            history = model.fit(x_train2, y_train2,\n",
    "                                batch_size=batch_size,\n",
    "                                epochs=epochs,\n",
    "                                verbose=1,\n",
    "                                validation_data=(x_val, y_val),\n",
    "                                callbacks=[callback])  \n",
    "            \n",
    "            if history.history['val_accuracy'][-1]>best_acc:\n",
    "                best_acc=history.history['val_accuracy'][-1]\n",
    "                besthden = hden\n",
    "                besthdim = hdim\n",
    "                bestl_rate= l_rate\n",
    "\n",
    "print(\"=============================\")\n",
    "print(\"Best acc\", best_acc)\n",
    "print(\"Best hden\", besthden)\n",
    "print(\"Best hdim\", besthdim)\n",
    "print(\"Best learning rate\",bestl_rate)\n",
    "print(\"=============================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9826666712760925\n",
      "3\n",
      "1024\n",
      "0.025\n"
     ]
    }
   ],
   "source": [
    "print(best_acc)\n",
    "print(besthden)\n",
    "print(besthdim)\n",
    "print(bestl_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "469/469 [==============================] - 6s 11ms/step - loss: 0.3003 - accuracy: 0.9133 - val_loss: 0.1304 - val_accuracy: 0.9595\n",
      "Epoch 2/100\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.1015 - accuracy: 0.9697 - val_loss: 0.1025 - val_accuracy: 0.9697\n",
      "Epoch 3/100\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.0649 - accuracy: 0.9805 - val_loss: 0.0735 - val_accuracy: 0.9777\n",
      "Epoch 4/100\n",
      "469/469 [==============================] - 7s 14ms/step - loss: 0.0443 - accuracy: 0.9862 - val_loss: 0.0655 - val_accuracy: 0.9796\n",
      "Epoch 5/100\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0313 - accuracy: 0.9903 - val_loss: 0.0802 - val_accuracy: 0.9770\n",
      "Epoch 6/100\n",
      "469/469 [==============================] - 7s 15ms/step - loss: 0.0209 - accuracy: 0.9940 - val_loss: 0.0651 - val_accuracy: 0.9815\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## PROBAR EL MEJOR CON TEST\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(784))\n",
    "for i in range(besthden):\n",
    "    model.add(Dense(besthdim, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "sgd=SGD(learning_rate=bestl_rate, momentum=0.9)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3) ## También podría ser 'loss' sin necesitar un conjunto de validación\n",
    "history = model.fit(x_train, y_train, # <--- aquí podríamos concatenar trainin+valid para no malgastar datos\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[callback])  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9815000295639038"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model checkpoint\n",
    "\n",
    "Los model checkpoint permiten almacenar el estado del modelo en un punto intermedio del entrenamiento. Esto es útil para poder recuperar el modelo en caso de que el entrenamiento se interrumpa por cualquier motivo. Así como para poder recuperar el mejor modelo obtenido durante el entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/375 [============================>.] - ETA: 0s - loss: 0.5034 - accuracy: 0.8629\n",
      "Epoch 1: val_accuracy improved from -inf to 0.91900, saving model to best_model.h5\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4963 - accuracy: 0.8646 - val_loss: 0.2893 - val_accuracy: 0.9190\n",
      "Epoch 2/100\n",
      " 41/375 [==>...........................] - ETA: 1s - loss: 0.2824 - accuracy: 0.9204"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pegi/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362/375 [===========================>..] - ETA: 0s - loss: 0.2622 - accuracy: 0.9267\n",
      "Epoch 2: val_accuracy improved from 0.91900 to 0.93525, saving model to best_model.h5\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2612 - accuracy: 0.9272 - val_loss: 0.2343 - val_accuracy: 0.9352\n",
      "Epoch 3/100\n",
      "368/375 [============================>.] - ETA: 0s - loss: 0.2123 - accuracy: 0.9409\n",
      "Epoch 3: val_accuracy improved from 0.93525 to 0.94625, saving model to best_model.h5\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2120 - accuracy: 0.9411 - val_loss: 0.1953 - val_accuracy: 0.9463\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.1778 - accuracy: 0.9505\n",
      "Epoch 4: val_accuracy improved from 0.94625 to 0.95233, saving model to best_model.h5\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1778 - accuracy: 0.9505 - val_loss: 0.1743 - val_accuracy: 0.9523\n",
      "Epoch 5/100\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.1537 - accuracy: 0.9579\n",
      "Epoch 5: val_accuracy improved from 0.95233 to 0.95675, saving model to best_model.h5\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1538 - accuracy: 0.9579 - val_loss: 0.1544 - val_accuracy: 0.9567\n",
      "Epoch 6/100\n",
      "362/375 [===========================>..] - ETA: 0s - loss: 0.1352 - accuracy: 0.9628\n",
      "Epoch 6: val_accuracy improved from 0.95675 to 0.96058, saving model to best_model.h5\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1344 - accuracy: 0.9630 - val_loss: 0.1418 - val_accuracy: 0.9606\n",
      "Epoch 7/100\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.1201 - accuracy: 0.9676\n",
      "Epoch 7: val_accuracy improved from 0.96058 to 0.96325, saving model to best_model.h5\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1199 - accuracy: 0.9676 - val_loss: 0.1310 - val_accuracy: 0.9632\n",
      "Epoch 8/100\n",
      "363/375 [============================>.] - ETA: 0s - loss: 0.1075 - accuracy: 0.9707\n",
      "Epoch 8: val_accuracy improved from 0.96325 to 0.96558, saving model to best_model.h5\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1078 - accuracy: 0.9707 - val_loss: 0.1216 - val_accuracy: 0.9656\n",
      "Epoch 9/100\n",
      "363/375 [============================>.] - ETA: 0s - loss: 0.0988 - accuracy: 0.9732\n",
      "Epoch 9: val_accuracy improved from 0.96558 to 0.96625, saving model to best_model.h5\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0981 - accuracy: 0.9734 - val_loss: 0.1175 - val_accuracy: 0.9663\n",
      "Epoch 10/100\n",
      "363/375 [============================>.] - ETA: 0s - loss: 0.0904 - accuracy: 0.9762\n",
      "Epoch 10: val_accuracy improved from 0.96625 to 0.96850, saving model to best_model.h5\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0897 - accuracy: 0.9764 - val_loss: 0.1101 - val_accuracy: 0.9685\n",
      "Epoch 11/100\n",
      "364/375 [============================>.] - ETA: 0s - loss: 0.0825 - accuracy: 0.9783\n",
      "Epoch 11: val_accuracy improved from 0.96850 to 0.96967, saving model to best_model.h5\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0824 - accuracy: 0.9782 - val_loss: 0.1044 - val_accuracy: 0.9697\n",
      "Epoch 12/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0762 - accuracy: 0.9804\n",
      "Epoch 12: val_accuracy improved from 0.96967 to 0.97117, saving model to best_model.h5\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0760 - accuracy: 0.9804 - val_loss: 0.0994 - val_accuracy: 0.9712\n",
      "Epoch 13/100\n",
      "364/375 [============================>.] - ETA: 0s - loss: 0.0702 - accuracy: 0.9816\n",
      "Epoch 13: val_accuracy improved from 0.97117 to 0.97208, saving model to best_model.h5\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0704 - accuracy: 0.9816 - val_loss: 0.0958 - val_accuracy: 0.9721\n",
      "Epoch 14/100\n",
      "364/375 [============================>.] - ETA: 0s - loss: 0.0653 - accuracy: 0.9834\n",
      "Epoch 14: val_accuracy improved from 0.97208 to 0.97267, saving model to best_model.h5\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0652 - accuracy: 0.9833 - val_loss: 0.0930 - val_accuracy: 0.9727\n",
      "Epoch 15/100\n",
      "366/375 [============================>.] - ETA: 0s - loss: 0.0614 - accuracy: 0.9839\n",
      "Epoch 15: val_accuracy did not improve from 0.97267\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0612 - accuracy: 0.9840 - val_loss: 0.0926 - val_accuracy: 0.9726\n",
      "Epoch 16/100\n",
      "365/375 [============================>.] - ETA: 0s - loss: 0.0571 - accuracy: 0.9850\n",
      "Epoch 16: val_accuracy improved from 0.97267 to 0.97433, saving model to best_model.h5\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0573 - accuracy: 0.9851 - val_loss: 0.0881 - val_accuracy: 0.9743\n",
      "Epoch 17/100\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0534 - accuracy: 0.9869\n",
      "Epoch 17: val_accuracy did not improve from 0.97433\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0533 - accuracy: 0.9870 - val_loss: 0.0863 - val_accuracy: 0.9741\n",
      "Test loss: 0.08105669915676117\n",
      "Test accuracy: 0.9769999980926514\n"
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "epochs=100 \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(784))\n",
    "model.add(Dense(1024, activation='relu')) \n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "sgd=SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    " \n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3) \n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "\n",
    "model.fit(x_train2, y_train2,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[callback, checkpoint]) ## <--- dos callbacks, el early_stopping y el model_checkpoint\n",
    "\n",
    "\n",
    "## Cargar el mejor modelo y evaluarlo con el test set\n",
    "model = keras.models.load_model('best_model.h5')\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajustar parámetros\n",
    "\n",
    "Es posible que en el ejemplo anterior el entrenamiento haya acabado prematuramente por el efecto del Early Stopping. En ese caso, el modelo que se ha obtenido no es el mejor posible. Para obtener el mejor modelo quizás sea necesario aumentar el número de epochs y para ello modificar algún parámetro del early stopping.\n",
    "\n",
    "## Ejercicio: \n",
    "\n",
    "Modificar el early stopping y emplear un modelo con los mejores parámetros (número de capas ocultas, learning rate, batch size, etc) para evaluar finalmente el modelo guardado sobre el test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.3432 - accuracy: 0.9018\n",
      "Epoch 1: val_accuracy improved from -inf to 0.95792, saving model to best_model.h5\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3426 - accuracy: 0.9020 - val_loss: 0.1449 - val_accuracy: 0.9579\n",
      "Epoch 2/100\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.1141 - accuracy: 0.9653\n",
      "Epoch 2: val_accuracy improved from 0.95792 to 0.97067, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.1141 - accuracy: 0.9653 - val_loss: 0.1001 - val_accuracy: 0.9707\n",
      "Epoch 3/100\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0744 - accuracy: 0.9781\n",
      "Epoch 3: val_accuracy improved from 0.97067 to 0.97308, saving model to best_model.h5\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0742 - accuracy: 0.9781 - val_loss: 0.0849 - val_accuracy: 0.9731\n",
      "Epoch 4/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0522 - accuracy: 0.9843\n",
      "Epoch 4: val_accuracy improved from 0.97308 to 0.97758, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0522 - accuracy: 0.9843 - val_loss: 0.0790 - val_accuracy: 0.9776\n",
      "Epoch 5/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0352 - accuracy: 0.9897\n",
      "Epoch 5: val_accuracy did not improve from 0.97758\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0351 - accuracy: 0.9897 - val_loss: 0.0767 - val_accuracy: 0.9772\n",
      "Epoch 6/100\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0243 - accuracy: 0.9931\n",
      "Epoch 6: val_accuracy improved from 0.97758 to 0.98125, saving model to best_model.h5\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0242 - accuracy: 0.9931 - val_loss: 0.0681 - val_accuracy: 0.9812\n",
      "Epoch 7/100\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9959\n",
      "Epoch 7: val_accuracy did not improve from 0.98125\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0159 - accuracy: 0.9959 - val_loss: 0.0745 - val_accuracy: 0.9779\n",
      "Epoch 8/100\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9973\n",
      "Epoch 8: val_accuracy did not improve from 0.98125\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0106 - accuracy: 0.9971 - val_loss: 0.0704 - val_accuracy: 0.9797\n",
      "Epoch 9/100\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9980\n",
      "Epoch 9: val_accuracy did not improve from 0.98125\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0083 - accuracy: 0.9980 - val_loss: 0.0785 - val_accuracy: 0.9808\n",
      "Epoch 1/100\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.3473 - accuracy: 0.8977\n",
      "Epoch 1: val_accuracy improved from -inf to 0.95108, saving model to best_model.h5\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3459 - accuracy: 0.8981 - val_loss: 0.1555 - val_accuracy: 0.9511\n",
      "Epoch 2/100\n",
      "369/375 [============================>.] - ETA: 0s - loss: 0.1153 - accuracy: 0.9663\n",
      "Epoch 2: val_accuracy improved from 0.95108 to 0.96583, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.1155 - accuracy: 0.9662 - val_loss: 0.1104 - val_accuracy: 0.9658\n",
      "Epoch 3/100\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0743 - accuracy: 0.9771\n",
      "Epoch 3: val_accuracy improved from 0.96583 to 0.96725, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0743 - accuracy: 0.9771 - val_loss: 0.1056 - val_accuracy: 0.9672\n",
      "Epoch 4/100\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0497 - accuracy: 0.9849\n",
      "Epoch 4: val_accuracy improved from 0.96725 to 0.97642, saving model to best_model.h5\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0502 - accuracy: 0.9847 - val_loss: 0.0852 - val_accuracy: 0.9764\n",
      "Epoch 5/100\n",
      "369/375 [============================>.] - ETA: 0s - loss: 0.0358 - accuracy: 0.9896\n",
      "Epoch 5: val_accuracy improved from 0.97642 to 0.97675, saving model to best_model.h5\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0359 - accuracy: 0.9896 - val_loss: 0.0780 - val_accuracy: 0.9768\n",
      "Epoch 6/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0250 - accuracy: 0.9925\n",
      "Epoch 6: val_accuracy improved from 0.97675 to 0.97967, saving model to best_model.h5\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.0251 - accuracy: 0.9925 - val_loss: 0.0712 - val_accuracy: 0.9797\n",
      "Epoch 7/100\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0170 - accuracy: 0.9952\n",
      "Epoch 7: val_accuracy improved from 0.97967 to 0.98042, saving model to best_model.h5\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 0.0703 - val_accuracy: 0.9804\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.9970\n",
      "Epoch 8: val_accuracy did not improve from 0.98042\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.0124 - accuracy: 0.9970 - val_loss: 0.0781 - val_accuracy: 0.9777\n",
      "Epoch 9/100\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9984\n",
      "Epoch 9: val_accuracy did not improve from 0.98042\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0075 - accuracy: 0.9984 - val_loss: 0.0773 - val_accuracy: 0.9790\n",
      "Epoch 1/100\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.3413 - accuracy: 0.9012\n",
      "Epoch 1: val_accuracy improved from -inf to 0.94458, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.3384 - accuracy: 0.9020 - val_loss: 0.1752 - val_accuracy: 0.9446\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.1164 - accuracy: 0.9650\n",
      "Epoch 2: val_accuracy improved from 0.94458 to 0.96617, saving model to best_model.h5\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1164 - accuracy: 0.9650 - val_loss: 0.1126 - val_accuracy: 0.9662\n",
      "Epoch 3/100\n",
      "369/375 [============================>.] - ETA: 0s - loss: 0.0720 - accuracy: 0.9781\n",
      "Epoch 3: val_accuracy improved from 0.96617 to 0.97508, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0725 - accuracy: 0.9780 - val_loss: 0.0866 - val_accuracy: 0.9751\n",
      "Epoch 4/100\n",
      "369/375 [============================>.] - ETA: 0s - loss: 0.0514 - accuracy: 0.9844\n",
      "Epoch 4: val_accuracy improved from 0.97508 to 0.97725, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0511 - accuracy: 0.9845 - val_loss: 0.0771 - val_accuracy: 0.9772\n",
      "Epoch 5/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0345 - accuracy: 0.9894\n",
      "Epoch 5: val_accuracy improved from 0.97725 to 0.97742, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.0344 - accuracy: 0.9895 - val_loss: 0.0757 - val_accuracy: 0.9774\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 0.9931\n",
      "Epoch 6: val_accuracy improved from 0.97742 to 0.97967, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0231 - accuracy: 0.9931 - val_loss: 0.0697 - val_accuracy: 0.9797\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9950\n",
      "Epoch 7: val_accuracy did not improve from 0.97967\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0174 - accuracy: 0.9950 - val_loss: 0.0865 - val_accuracy: 0.9754\n",
      "Epoch 8/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9969\n",
      "Epoch 8: val_accuracy improved from 0.97967 to 0.98050, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0785 - val_accuracy: 0.9805\n",
      "Epoch 9/100\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9985\n",
      "Epoch 9: val_accuracy did not improve from 0.98050\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.0071 - accuracy: 0.9985 - val_loss: 0.0817 - val_accuracy: 0.9791\n",
      "Epoch 1/100\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.3443 - accuracy: 0.8984\n",
      "Epoch 1: val_accuracy improved from -inf to 0.95342, saving model to best_model.h5\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3418 - accuracy: 0.8992 - val_loss: 0.1585 - val_accuracy: 0.9534\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.1134 - accuracy: 0.9662\n",
      "Epoch 2: val_accuracy improved from 0.95342 to 0.96925, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.1134 - accuracy: 0.9662 - val_loss: 0.1044 - val_accuracy: 0.9693\n",
      "Epoch 3/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0745 - accuracy: 0.9773\n",
      "Epoch 3: val_accuracy improved from 0.96925 to 0.97000, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0748 - accuracy: 0.9772 - val_loss: 0.0992 - val_accuracy: 0.9700\n",
      "Epoch 4/100\n",
      "372/375 [============================>.] - ETA: 0s - loss: 0.0511 - accuracy: 0.9845\n",
      "Epoch 4: val_accuracy improved from 0.97000 to 0.97575, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.0510 - accuracy: 0.9845 - val_loss: 0.0833 - val_accuracy: 0.9758\n",
      "Epoch 5/100\n",
      "370/375 [============================>.] - ETA: 0s - loss: 0.0368 - accuracy: 0.9891\n",
      "Epoch 5: val_accuracy improved from 0.97575 to 0.97633, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.0366 - accuracy: 0.9891 - val_loss: 0.0738 - val_accuracy: 0.9763\n",
      "Epoch 6/100\n",
      "374/375 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 0.9924\n",
      "Epoch 6: val_accuracy improved from 0.97633 to 0.98058, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.0251 - accuracy: 0.9924 - val_loss: 0.0677 - val_accuracy: 0.9806\n",
      "Epoch 7/100\n",
      "373/375 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.9947\n",
      "Epoch 7: val_accuracy did not improve from 0.98058\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0184 - accuracy: 0.9946 - val_loss: 0.0755 - val_accuracy: 0.9780\n",
      "Epoch 8/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0126 - accuracy: 0.9967\n",
      "Epoch 8: val_accuracy improved from 0.98058 to 0.98067, saving model to best_model.h5\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0125 - accuracy: 0.9967 - val_loss: 0.0732 - val_accuracy: 0.9807\n",
      "Epoch 9/100\n",
      "371/375 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9986\n",
      "Epoch 9: val_accuracy did not improve from 0.98067\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.0817 - val_accuracy: 0.9796\n",
      "Test loss: 0.07162820547819138\n",
      "Test accuracy: 0.979200005531311\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "best_acc = 0.9826666712760925\n",
    "besthden = 3\n",
    "besthdim = 1024\n",
    "bestl_rate = 0.025\n",
    "\n",
    "batch_size=128\n",
    "epochs=100 \n",
    "for min_d in [0.01,0.001,0.0001,0.00001]:\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(784))\n",
    "    for _ in range(besthden):\n",
    "        model.add(Dense(besthdim, activation='relu')) \n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    sgd=SGD(learning_rate=bestl_rate, momentum=0.9)\n",
    "\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=sgd,\n",
    "                metrics=['accuracy'])\n",
    "        \n",
    "    \n",
    "\n",
    "    callback = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=min_d , patience=3) \n",
    "\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "\n",
    "    model.fit(x_train2, y_train2,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        callbacks=[callback, checkpoint]) ## <--- dos callbacks, el early_stopping y el model_checkpoint\n",
    "\n",
    "\n",
    "## Cargar el mejor modelo y evaluarlo con el test set\n",
    "model = keras.models.load_model('best_model.h5')\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variaciones sobre el modelo inicial \n",
    "\n",
    "Vamos a implementar alguna modificación sobre el modelo inicial propuesto en la primera sesión.\n",
    "\n",
    "Para empezar vamos a definir un conjunto de validación. Con este conjunto de calidación extraído del propio conjunto de entrenamiento estimaremos los mejores parámetros. Dejaremos el conjunto de test sólo para estimar el acierto final con estos mejores parámetros.\n",
    "\n",
    "Primero leemos los datos y normalizamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 22:49:43.306284: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-11 22:49:43.344662: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-11 22:49:43.509323: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-11 22:49:43.509355: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-11 22:49:43.510441: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-11 22:49:43.586943: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-11 22:49:43.588120: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-11 22:49:44.750190: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set (60000, 28, 28)\n",
      "test set (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print('training set', x_train.shape)\n",
    "print('test set', x_test.shape)\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalize [0..255]-->[0..1]\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "num_classes=10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partición training/validación\n",
    "\n",
    "Nos quedaremos con un 80% de los datos para entrenar y un 20% para validar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set (48000, 784)\n",
      "val set (12000, 784)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print('training set', x_train.shape)\n",
    "print('val set', x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentación con conjunto de validación\n",
    "\n",
    "Cualquier parámetro a modificar en nuestro modelo debería ser probado sobre el conjunto de validación y escoger aquel que produjera el mejor resultado para probar ese (y sólo ese) sobre el conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5401 - accuracy: 0.8516 - val_loss: 0.3158 - val_accuracy: 0.9123\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.2854 - accuracy: 0.9193 - val_loss: 0.2567 - val_accuracy: 0.9273\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2366 - accuracy: 0.9336 - val_loss: 0.2231 - val_accuracy: 0.9368\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.2034 - accuracy: 0.9424 - val_loss: 0.1977 - val_accuracy: 0.9440\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.1789 - accuracy: 0.9496 - val_loss: 0.1767 - val_accuracy: 0.9513\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.5235 - accuracy: 0.8560 - val_loss: 0.3005 - val_accuracy: 0.9166\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2693 - accuracy: 0.9243 - val_loss: 0.2407 - val_accuracy: 0.9324\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2182 - accuracy: 0.9389 - val_loss: 0.2036 - val_accuracy: 0.9437\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1848 - accuracy: 0.9484 - val_loss: 0.1808 - val_accuracy: 0.9495\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.1604 - accuracy: 0.9553 - val_loss: 0.1627 - val_accuracy: 0.9544\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.5089 - accuracy: 0.8612 - val_loss: 0.2996 - val_accuracy: 0.9171\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.2685 - accuracy: 0.9245 - val_loss: 0.2402 - val_accuracy: 0.9343\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.2187 - accuracy: 0.9390 - val_loss: 0.2046 - val_accuracy: 0.9433\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1839 - accuracy: 0.9484 - val_loss: 0.1781 - val_accuracy: 0.9517\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.1591 - accuracy: 0.9555 - val_loss: 0.1599 - val_accuracy: 0.9562\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.4912 - accuracy: 0.8663 - val_loss: 0.2943 - val_accuracy: 0.9183\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2615 - accuracy: 0.9266 - val_loss: 0.2320 - val_accuracy: 0.9338\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2104 - accuracy: 0.9414 - val_loss: 0.1983 - val_accuracy: 0.9447\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1774 - accuracy: 0.9507 - val_loss: 0.1722 - val_accuracy: 0.9525\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1535 - accuracy: 0.9580 - val_loss: 0.1550 - val_accuracy: 0.9571\n",
      "=============================\n",
      "Best acc 0.9570833444595337\n",
      "Best hidden dim 1024\n",
      "=============================\n",
      "Epoch 1/5\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4929 - accuracy: 0.8673 - val_loss: 0.2818 - val_accuracy: 0.9211\n",
      "Epoch 2/5\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2583 - accuracy: 0.9281 - val_loss: 0.2209 - val_accuracy: 0.9376\n",
      "Epoch 3/5\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2080 - accuracy: 0.9431 - val_loss: 0.1899 - val_accuracy: 0.9445\n",
      "Epoch 4/5\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1761 - accuracy: 0.9512 - val_loss: 0.1641 - val_accuracy: 0.9543\n",
      "Epoch 5/5\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1518 - accuracy: 0.9576 - val_loss: 0.1453 - val_accuracy: 0.9578\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "batch_size=128\n",
    "epochs=5  \n",
    "\n",
    "hdim=[128,256,512,1024]\n",
    "best_acc=0.0\n",
    "for h in hdim:\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(784))\n",
    "    model.add(Dense(h, activation='relu')) # <-- repetir esta línea tantas veces como número de capas ocultas se quiera\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    sgd=SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    " \n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val, y_val)) ## <--- OJO validation set\n",
    "    \n",
    "    if history.history['val_accuracy'][-1]>best_acc:\n",
    "        best_acc=history.history['val_accuracy'][-1]\n",
    "        besth=h\n",
    "\n",
    "print(\"=============================\")\n",
    "print(\"Best acc\",best_acc)\n",
    "print(\"Best hidden dim\",besth)\n",
    "print(\"=============================\")\n",
    "\n",
    "\n",
    "## PROBAR EL MEJOR CON TEST\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(784))\n",
    "model.add(Dense(besth, activation='relu'))  \n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "sgd=SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, # <--- aquí podríamos concatenar trainin+valid para no malgastar datos\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EARLY STOPPING\n",
    "\n",
    "De la multitud de parámetros a decidir en la definición y entrenamiento de las redes neuronales hay uno que podríamos automatizar. Es el número de epochs a emplear. Dado que tenemos un conjunto de validación vamos a emplearlo para monitorizar cómo evoluciona la convergencia. Si en algún momento el descenso por gradiente parece haber alcanzado una zona de meseta sobre dicho conjunto de validación podremos detener el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.4909 - accuracy: 0.8679 - val_loss: 0.2930 - val_accuracy: 0.9178\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2615 - accuracy: 0.9260 - val_loss: 0.2326 - val_accuracy: 0.9369\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.2112 - accuracy: 0.9417 - val_loss: 0.1966 - val_accuracy: 0.9474\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1770 - accuracy: 0.9511 - val_loss: 0.1732 - val_accuracy: 0.9527\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1528 - accuracy: 0.9573 - val_loss: 0.1563 - val_accuracy: 0.9578\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1347 - accuracy: 0.9635 - val_loss: 0.1418 - val_accuracy: 0.9603\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1199 - accuracy: 0.9671 - val_loss: 0.1316 - val_accuracy: 0.9633\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1078 - accuracy: 0.9711 - val_loss: 0.1211 - val_accuracy: 0.9674\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0980 - accuracy: 0.9737 - val_loss: 0.1137 - val_accuracy: 0.9684\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0897 - accuracy: 0.9764 - val_loss: 0.1089 - val_accuracy: 0.9698\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0823 - accuracy: 0.9781 - val_loss: 0.1047 - val_accuracy: 0.9701\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0757 - accuracy: 0.9800 - val_loss: 0.0987 - val_accuracy: 0.9723\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0705 - accuracy: 0.9816 - val_loss: 0.0957 - val_accuracy: 0.9728\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0651 - accuracy: 0.9836 - val_loss: 0.0932 - val_accuracy: 0.9735\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0608 - accuracy: 0.9844 - val_loss: 0.0889 - val_accuracy: 0.9747\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Input(784))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "sgd=SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3) ## También podría ser 'loss' sin necesitar un conjunto de validación\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs=100  ## No nos preocupemos, el fit acabará antes por el early_stopping\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[callback])  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Ejercicio**:\n",
    "\n",
    "Entrenar una red neuronal MLP para el problema MNIST. Los valores que se quieren probar son los siguientes:\n",
    "\n",
    "-   Número de capas ocultas [1,2,3]\n",
    "-   Dimensión de las capas ocultas [512,1024]\n",
    "-   Learning rate [0.01, 0.001, 0.0001]\n",
    "-   Batch_size [128]\n",
    "-   Epochs con early_stopping\n",
    "\n",
    "Obtener la mejor combinación con el conjunto de validación y probarla finalmente sobre el conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.5041 - accuracy: 0.8595 - val_loss: 0.2536 - val_accuracy: 0.9298\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.2246 - accuracy: 0.9358 - val_loss: 0.1944 - val_accuracy: 0.9437\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1678 - accuracy: 0.9526 - val_loss: 0.1647 - val_accuracy: 0.9515\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1317 - accuracy: 0.9631 - val_loss: 0.1406 - val_accuracy: 0.9592\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.1090 - accuracy: 0.9688 - val_loss: 0.1190 - val_accuracy: 0.9663\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0907 - accuracy: 0.9745 - val_loss: 0.1077 - val_accuracy: 0.9688\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0775 - accuracy: 0.9780 - val_loss: 0.0999 - val_accuracy: 0.9697\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0658 - accuracy: 0.9814 - val_loss: 0.0916 - val_accuracy: 0.9732\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0576 - accuracy: 0.9844 - val_loss: 0.0899 - val_accuracy: 0.9730\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0502 - accuracy: 0.9859 - val_loss: 0.0887 - val_accuracy: 0.9735\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0446 - accuracy: 0.9880 - val_loss: 0.0815 - val_accuracy: 0.9749\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0376 - accuracy: 0.9906 - val_loss: 0.0793 - val_accuracy: 0.9748\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0334 - accuracy: 0.9916 - val_loss: 0.0778 - val_accuracy: 0.9759\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0296 - accuracy: 0.9931 - val_loss: 0.0751 - val_accuracy: 0.9767\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0224 - accuracy: 0.9961 - val_loss: 0.0726 - val_accuracy: 0.9775\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0215 - accuracy: 0.9963 - val_loss: 0.0718 - val_accuracy: 0.9779\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0211 - accuracy: 0.9963 - val_loss: 0.0717 - val_accuracy: 0.9779\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0207 - accuracy: 0.9964 - val_loss: 0.0717 - val_accuracy: 0.9778\n",
      "Epoch 1/100\n",
      "375/375 [==============================] - 3s 6ms/step - loss: 0.0201 - accuracy: 0.9967 - val_loss: 0.0717 - val_accuracy: 0.9780\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0201 - accuracy: 0.9967 - val_loss: 0.0717 - val_accuracy: 0.9780\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0200 - accuracy: 0.9968 - val_loss: 0.0717 - val_accuracy: 0.9781\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0200 - accuracy: 0.9967 - val_loss: 0.0717 - val_accuracy: 0.9781\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Input(784))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "batch_size = 128\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3) ## También podría ser 'loss' sin necesitar un conjunto de validación\n",
    "\n",
    "for lr in learning_rates:\n",
    "    sgd=SGD(learning_rate=lr, momentum=0.9)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    epochs=100  ## No nos preocupemos, el fit acabará antes por el early_stopping\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        callbacks=[callback])\n",
    "    \n",
    "    if history.history['val_accuracy'][-1]>best_acc:\n",
    "        best_acc=history.history['val_accuracy'][-1]\n",
    "        besth=h\n",
    "\n",
    "print(\"=============================\")\n",
    "print(\"Best acc\",best_acc)\n",
    "print(\"Best hidden dim\",besth)\n",
    "print(\"=============================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

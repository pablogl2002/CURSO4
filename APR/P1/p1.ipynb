{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeros modelos KERAS sobre MNIST\n",
    "\n",
    "Vamos a implementar las primeras redes neuronales para el conjunto de datos MNIST\n",
    "\n",
    "IMPORTAMOS el Dataset y lo normalizamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print('training set', x_train.shape)\n",
    "print('test set', x_test.shape)\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalize [0..255]-->[0..1]\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "num_classes=10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos secuenciales en KERAS\n",
    "\n",
    "Los modelos secuenciales son modelos donde las capas se van añadiendo una tras otra. Te permite crear topologías básicas sin conexiones que no sean estrictamente lineales.\n",
    "\n",
    "La red neuronal a crear es la siguiente:\n",
    "\n",
    "- Capa de entrada de 784 neuronas, acorde con la dimensionalidad de los datos\n",
    "- Capa oculta de 512 neuronas, con función de activación ReLU\n",
    "- Capa de salida de 10 neuronas, acorde con el número de clases. Al ser un problema de clasificación emplearemos la función de activación Softmax\n",
    "\n",
    "Este sería la definición del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(784))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model summary](summary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El summary del modelo nos lista las diferentes capas del mismo así como su número de parámetros. Por ejemplo la capa densa oculta tiene 784 entradas x 512 salidas lo que implica una matriz de 784x512 = 401408 componentes. Además esta capa Dense tiene un vector de bias de 512 componentes, por lo tanto en total son 401408+512 = **401920**, que coincide con el número de parámetros de la tabla para dicha capa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos generar una imagen con la topología del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, to_file=\"model.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilar el modelo \n",
    "\n",
    "Para terminar la definición de nuestro modelo debemos definir dos componentes muy importantes:\n",
    "\n",
    "1. Función de pérdida. En nuestro caso al ser un problema de clasificación emplearemos la **categorical_crossentropy**\n",
    "2. Optimizador. En nuestro caso y para empezar emplearemos un sencillo descenso por gradiente estocástico **SGD**\n",
    "\n",
    "opcionalmente:\n",
    "\n",
    "3. Definir una métrica asociada a la calidad del modelo. En nuestro caso sería la tasa de acierto **accuracy**\n",
    "\n",
    "\n",
    "Una vez definidos pasamos a compilar el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "sgd=SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "# Compile Model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar el modelo\n",
    "\n",
    "Una vez tenemos los datos cargados y normalizados, así como el modelo ya compilado, podemos realizar el entrenamiento mediante el método **fit**. Para ello previamente necesitamos definir el tamaño del batch así como el número de epochs.\n",
    "\n",
    "Al mismo tiempo que entrenamos el modelo con los datos de entrenamiento vamos a ir evaluando dicho modelo sobre los datos de test. Además, vamos generando un **history** con la evolución del modelo para luego poder crear gráficas del mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "epochs=25\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorar el History\n",
    "\n",
    "Realizar gráfica con resultados de accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizar gráfica con resultados de loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejercicio** \n",
    "\n",
    "probar diferentes entrenamientos dependiendo de los siguientes valores y anotar el accuracy en test alcanzado\n",
    "\n",
    "| Dense/Batch  | 16  | 32  |  64 | 128  |\n",
    "|---|---|---|---|---|\n",
    "|  256  |   |   |   |   |\n",
    "|  512  |   |   |   |   |\n",
    "|  1024 |   |   |   |   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvar y cargar el modelo\n",
    "\n",
    "Normalmente necesitaremos salvar el modelo entrenado para emplearlo más tarde en producción (inferencia)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos y normalizar\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print('training set', x_train.shape)\n",
    "print('test set', x_test.shape)\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "num_classes=10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# crear modelo y entrenar\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(784))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "sgd=SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "batch_size=32\n",
    "epochs=25\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "\n",
    "\n",
    "# guardar modelo\n",
    "model.save(\"model.keras\")\n",
    "\n",
    "# cargar modelo\n",
    "from keras.models import load_model\n",
    "model = load_model(\"model.keras\")\n",
    "\n",
    "# evaluar modelo\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

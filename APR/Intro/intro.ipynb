{"cells":[{"cell_type":"markdown","metadata":{},"source":["# MultiLayer Perceptron con el conjunto de datos MNIST\n","\n","MNIST es un conjunto de datos que representa una tarea de clasificación de pequeñas imágenes (28x28 píxeles). Las imágenes se agrupan en 10 clases, los dígitos del 0 al 9.\n","\n","Aunque es una tarea de clasificación de imágenes vamos a emplear topologías de redes neuronales MLP en lugar de topologías más avanzadas (segunda práctica de APR) basadas en redes convolucionales. El motivo de esta decisión es que MNIST es un conunto ampliamente empleado por lo que el alumno podrá encontrar muchas referencias e incluso compararse con el estado del arte en esta tarea.\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Imágenes de MNIST\n","\n","Un ejemplo de una de las imágenes del conjunto de datos disponible:\n","\n","![ejemplo mnist](mnist.webp)"]},{"cell_type":"markdown","metadata":{},"source":["### Representación lineal de las imágenes\n","\n","Se requiere una representación lineal (1D) de las imágenes para poder emplearlas como datos de entrada en un MLP. Para ellos lo usual es concatenar cada una de las filas de la imagen convirtiendo el tensor bidimensional (28x28) en un tensor unidimensional (784).\n","\n","![MNIST](mnist.gif \"MNIST\")"]},{"cell_type":"markdown","metadata":{},"source":["## Lectura de los datos y conversión con **Keras**\n","\n","Vamos a implemetar la importación de este conjunto de datos y la conversión en tensores unidimensionales. Para ello Keras nY numpy nos proveen de una serie de utilidades. "]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Collecting tensorflow\n","  Using cached tensorflow-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.8 MB)\n","Requirement already satisfied: packaging in /home/pegi/.local/lib/python3.10/site-packages (from tensorflow) (23.1)\n","Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n","Collecting opt-einsum>=2.3.2\n","  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n","Collecting wrapt<1.15,>=1.11.0\n","  Using cached wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n","Collecting tensorflow-io-gcs-filesystem>=0.23.1\n","  Using cached tensorflow_io_gcs_filesystem-0.34.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n","Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (59.6.0)\n","Collecting absl-py>=1.0.0\n","  Using cached absl_py-2.0.0-py3-none-any.whl (130 kB)\n","Collecting tensorflow-estimator<2.15,>=2.14.0\n","  Using cached tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n","Collecting google-pasta>=0.1.1\n","  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n","Collecting tensorboard<2.15,>=2.14\n","  Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hCollecting astunparse>=1.6.0\n","  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n","Collecting ml-dtypes==0.2.0\n","  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting termcolor>=1.1.0\n","  Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n","Collecting grpcio<2.0,>=1.24.3\n","  Using cached grpcio-1.59.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n","Collecting h5py>=2.9.0\n","  Downloading h5py-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hCollecting typing-extensions>=3.6.6\n","  Using cached typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n","Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n","  Using cached protobuf-4.24.3-cp37-abi3-manylinux2014_x86_64.whl (311 kB)\n","Requirement already satisfied: numpy>=1.23.5 in /home/pegi/.local/lib/python3.10/site-packages (from tensorflow) (1.24.3)\n","Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n","  Using cached gast-0.5.4-py3-none-any.whl (19 kB)\n","Collecting flatbuffers>=23.5.26\n","  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n","Collecting keras<2.15,>=2.14.0\n","  Downloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hCollecting libclang>=13.0.0\n","  Downloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n","Collecting werkzeug>=1.0.1\n","  Downloading werkzeug-3.0.0-py3-none-any.whl (226 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.6/226.6 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hCollecting markdown>=2.6.8\n","  Downloading Markdown-3.4.4-py3-none-any.whl (94 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.2/94.2 KB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.25.1)\n","Collecting google-auth-oauthlib<1.1,>=0.5\n","  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n","Collecting google-auth<3,>=1.6.3\n","  Downloading google_auth-2.23.2-py2.py3-none-any.whl (181 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.0/182.0 KB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0\n","  Downloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hCollecting rsa<5,>=3.1.4\n","  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n","Collecting cachetools<6.0,>=2.0.0\n","  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n","Collecting pyasn1-modules>=0.2.1\n","  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 KB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting requests-oauthlib>=0.7.0\n","  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n","Collecting MarkupSafe>=2.1.1\n","  Downloading MarkupSafe-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n","Collecting pyasn1<0.6.0,>=0.4.6\n","  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 KB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.0)\n","Installing collected packages: libclang, flatbuffers, wrapt, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, requests-oauthlib, pyasn1, protobuf, opt-einsum, ml-dtypes, MarkupSafe, markdown, keras, h5py, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, werkzeug, rsa, pyasn1-modules, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n","Successfully installed MarkupSafe-2.1.3 absl-py-2.0.0 astunparse-1.6.3 cachetools-5.3.1 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.23.2 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.59.0 h5py-3.9.0 keras-2.14.0 libclang-16.0.6 markdown-3.4.4 ml-dtypes-0.2.0 opt-einsum-3.3.0 protobuf-4.24.3 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.14.1 tensorboard-data-server-0.7.1 tensorflow-2.14.0 tensorflow-estimator-2.14.0 tensorflow-io-gcs-filesystem-0.34.0 termcolor-2.3.0 typing-extensions-4.8.0 werkzeug-3.0.0 wrapt-1.14.1\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install tensorflow"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-10-04 15:50:45.802584: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-10-04 15:50:45.804060: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n","2023-10-04 15:50:45.829979: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-10-04 15:50:45.830006: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-10-04 15:50:45.830033: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-10-04 15:50:45.834686: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n","2023-10-04 15:50:45.834960: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-10-04 15:50:46.552979: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 1s 0us/step\n","training set (60000, 28, 28)\n","test set (10000, 28, 28)\n","255\n"]}],"source":["## ASUMIENDO KERAS V2\n","\n","from tensorflow import keras\n","from keras.datasets import mnist\n","\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","print('training set', x_train.shape)\n","print('test set', x_test.shape)\n","\n","import numpy as np\n","print(np.max(x_train)) # <-- comprobar que las imágenes vienen normalizadas entre 0 y 255, niveles de gris de 8 bits"]},{"cell_type":"markdown","metadata":{},"source":["Importante resaltar que al importar MNIST tenemos en realidad dos conjuntos de datos: *training* y *test*. Además, por cada conjunto de datos tenemos dos arrays, uno con los datos (imágenes) y otro con las etiquetas (clases) asociadas a dichas imágenes.\n","\n","A continuación realizamos algunas modificaciones necesarias: \n","\n","1. convertimos los arrays a 1D\n","2. normalizamos los valores para que estén en el intervalo [0..1]\n","3. convertimos las etiquetas de clase en un one-hot vector"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x_train = x_train.reshape(60000, 784)\n","x_test = x_test.reshape(10000, 784)\n","x_train = x_train.astype('float32') # <-- convertir a float32 para que la normalización sea en coma flotante\n","x_test = x_test.astype('float32')\n","\n","# Normalize [0..255]-->[0..1]\n","x_train /= 255\n","x_test /= 255\n","\n","# convert class vectors to binary class matrices\n","num_classes=10\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)"]},{"cell_type":"markdown","metadata":{},"source":["Con este código estamos listos para crear las primeras redes neuronales MLP y entrenar los modelos"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
